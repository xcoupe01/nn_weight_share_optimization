{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREFIX = '../../'\n",
    "import sys\n",
    "sys.path.append(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.weight_sharing import *\n",
    "from data.imagenette import *\n",
    "from data.utils.download import *\n",
    "from data.utils.imagenet_utils import *\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "\n",
    "dat = ImagenetteDataset(BATCH_SIZE, os.path.join(PATH_PREFIX, 'data/imagenette/'), val_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test ', len(dat.test_dataset))\n",
    "print('val', len(dat.valid_dataset))\n",
    "print('train', len(dat.train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = get_accuracy(net, dat.test_dl, 'cpu', topk=1)\n",
    "#acc - 0.01 * acc\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_controller = WeightShare(net, lambda: get_accuracy(net, dat.test_dl, 'cpu', topk=1))\n",
    "ws_controller.print_layers_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_controller.model_layers[0].weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ws_controller.model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_controller.share([70, 96, 103, 120, 120, 120, 31, 120, 96, 120, 120, 117, 12, 55, 120, 63, 23, 73, 120, 28, 74, 12, 55, 106, 120, 102, 120, 13, 68, 65, 48, 69, 120, 22, 120, 71, 21, 120, 120, 57, 53, 91, 120, 120, 18, 120, 93, 32, 63, 120, 120, 120, 114], verbose=True, prec_reduct=['f4' for _ in ws_controller.model_layers], clust_alg='minibatch-kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = json.load(open(os.path.join(PATH_PREFIX, '/data/imagenette/imagenet_class_index.json')))\n",
    "classes_arr = []\n",
    "\n",
    "for i in range(len(classes.keys())):\n",
    "    classes_arr.append(classes[f'{i}'])\n",
    "\n",
    "output = net(dat.test_dl.__getitem__(1)[0].unsqueeze(0))\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(classes_arr[top5_catid[i]], top5_prob[i].item(), top5_catid[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
