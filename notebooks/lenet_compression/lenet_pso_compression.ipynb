{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO compression search on LeNet-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREFIX = '../../'\n",
    "import sys\n",
    "sys.path.append(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from data.mnist import MnistDataset\n",
    "from data.utils.mnist_utils import *\n",
    "from models.lenet.lenet import LeNet5\n",
    "from utils.weight_sharing import *\n",
    "from utils.pso import PSOController, Particle\n",
    "from utils.plot import *\n",
    "from utils.fitness_controller import FitnessController"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net train settings\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 10\n",
    "DEVICE = 'cpu'\n",
    "EPOCHS = 100\n",
    "\n",
    "# net save settings\n",
    "NET_TYPE = 'relu'\n",
    "NET_PATH = os.path.join(PATH_PREFIX, f'models/lenet/saves/lenet_{NET_TYPE}.save')\n",
    "\n",
    "# dataset settings\n",
    "DATA_PATH = os.path.join(PATH_PREFIX, 'data')\n",
    "\n",
    "# pso iter count\n",
    "NUM_ITERATIONS = 20\n",
    "NUM_PARTICLES = 20\n",
    "\n",
    "# pso search settings\n",
    "PARTICLE_REPR_RANGES = [range(1, 51) for _ in range(5)]\n",
    "PARTICLE_MAX_VELOCITY = [4 for _ in range(5)]\n",
    "INERTIA = 0.8\n",
    "\n",
    "# pso save settings\n",
    "SAVE_PSO_FILE = os.path.join(PATH_PREFIX, 'results/test_PSO_save.csv')\n",
    "SAVE_EVERY = 1\n",
    "\n",
    "# bh settings\n",
    "BH_RADUIUS = None #2\n",
    "BH_REPR_RAD = False\n",
    "BH_VEL_TRESHOLD = None #2\n",
    "\n",
    "# target position\n",
    "TARGET = [1.0, 12.0]\n",
    "TARGET_LOW_LIMIT = [0.95, 1.0]\n",
    "LOCK_TARGET = False\n",
    "TARGET_UPDATE_OFFSET = [0.001, 0.1]\n",
    "TOP_REPR_SET_INDIV = True\n",
    "\n",
    "# WS settings\n",
    "SHARE_ORDER = [0, 1, 2, 3, 4]\n",
    "RETRAIN_AMOUNT = None #[0, 0, 0, 0, 0]\n",
    "PREC_REDUCT = ['f4', 'f4', 'f4', 'f4', 'f4']\n",
    "CLUST_MOD_FOCUS = None #[0, 0, 0, 0, 0]\n",
    "CLUST_MOD_SPREAD = None #[0, 0, 0, 0, 0]\n",
    "MINI_BATCH_KMEANS = True\n",
    "\n",
    "# range optimization settings\n",
    "RANGE_OPTIMIZATION = True\n",
    "RANGE_OPTIMIZATION_TRESHOLD = 0.97\n",
    "RANGE_OPTIMIZATION_FILE = os.path.join(PATH_PREFIX, f'models/lenet/saves/lenet_{NET_TYPE}_layer_perf_{PREC_REDUCT[0]}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geting somewhat trained LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MnistDataset(BATCH_SIZE, DATA_PATH, val_split=0.5)\n",
    "model = LeNet5(N_CLASSES, NET_TYPE)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "train_settings = [criterion, optimizer, dataset, EPOCHS, DEVICE, 1, True]\n",
    "\n",
    "get_trained(model, NET_PATH, train_settings, DEVICE)\n",
    "\n",
    "before_loss = get_accuracy(model, dataset.test_dl, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_name #weights #bias w_locked CR\n",
      "feature_extractor.0 150 6 False 1.00\n",
      "feature_extractor.3 2400 16 False 1.00\n",
      "feature_extractor.6 48000 120 False 1.00\n",
      "classifier.0 10080 84 False 1.00\n",
      "classifier.2 840 10 False 1.00\n",
      "Sum num weights, bias:  61470 236\n",
      "Compression rate 1.00\n"
     ]
    }
   ],
   "source": [
    "lam_opt = lambda mod : torch.optim.Adam(mod.parameters(), lr=LEARNING_RATE)\n",
    "lam_train = lambda opt, epochs : train_net(model, criterion, opt, dataset, epochs, device=DEVICE)\n",
    "lam_test = lambda : get_accuracy(model, dataset.test_dl, DEVICE)\n",
    "\n",
    "ws_controller = WeightShare(model, lam_test, lam_opt, lam_train)\n",
    "ws_controller.set_reset()\n",
    "\n",
    "ws_controller.print_layers_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_vals_fc(individual:Particle):\n",
    "    # reset the net\n",
    "    ws_controller.reset()\n",
    "    \n",
    "    # share weigts by particle\n",
    "    if individual.data is None:\n",
    "        individual.data = ws_controller.share(individual.representation, SHARE_ORDER, RETRAIN_AMOUNT, PREC_REDUCT, CLUST_MOD_FOCUS, CLUST_MOD_SPREAD, minibatch_kmeans=MINI_BATCH_KMEANS)\n",
    "    \n",
    "    return [individual.data['accuracy'], individual.data['compression']]\n",
    "\n",
    "def fit_from_vals(data, targ_vals):\n",
    "\n",
    "    return 1 / math.sqrt(pow(1 - (data['accuracy']/targ_vals[0]), 2) + pow(1 - (data['compression']/targ_vals[1]), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define logging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'time': [],\n",
    "    'position': [],\n",
    "    'representation': [],\n",
    "    'velocity': [],\n",
    "    'accuracy': [],\n",
    "    'accuracy_loss': [],\n",
    "    'compression': [],\n",
    "    'share_t': [],\n",
    "    'train_t': [],\n",
    "    'acc_t': []\n",
    "}\n",
    "\n",
    "data_types = {\n",
    "    'time' : 'uint8',\n",
    "    'accuracy': 'float32',\n",
    "    'accuracy_loss': 'float32',\n",
    "    'compression': 'float32',\n",
    "    'share_t': 'float32',\n",
    "    'train_t': 'float32',\n",
    "    'acc_t': 'float32'\n",
    "}\n",
    "\n",
    "pso_data = pd.read_csv(SAVE_PSO_FILE).astype(data_types) if os.path.exists(SAVE_PSO_FILE) else pd.DataFrame(data).astype(data_types)\n",
    "\n",
    "def logger_fc(pso_cont:PSOController):\n",
    "    global pso_data\n",
    "\n",
    "    new_data = copy.deepcopy(data)\n",
    "\n",
    "    for particle in pso_cont.swarm:\n",
    "\n",
    "        new_data['time'].append(pso_cont.time)\n",
    "        new_data['position'].append(particle.position)\n",
    "        new_data['representation'].append(particle.representation)\n",
    "        new_data['velocity'].append(particle.velocity)\n",
    "        new_data['accuracy'].append(particle.data['accuracy'])\n",
    "        new_data['accuracy_loss'].append(before_loss - particle.data['accuracy'])\n",
    "        new_data['compression'].append(particle.data['compression'])\n",
    "        new_data['share_t'].append(particle.data['times']['share'])\n",
    "        new_data['train_t'].append(particle.data['times']['train'])\n",
    "        new_data['acc_t'].append(particle.data['times']['test'])\n",
    "\n",
    "    # saving progress\n",
    "    pso_data = pso_data.append(pd.DataFrame(new_data).astype(data_types))\n",
    "    if pso_cont.time % SAVE_EVERY == SAVE_EVERY - 1:\n",
    "        pso_data.reset_index(drop=True, inplace=True)\n",
    "        os.makedirs(os.path.dirname(SAVE_PSO_FILE), exist_ok=True)\n",
    "        pso_data.to_csv(SAVE_PSO_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "47\n",
      "47\n",
      "48\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "lam_test_inp = lambda _ : get_accuracy(model, dataset.test_dl, DEVICE)\n",
    "\n",
    "if RANGE_OPTIMIZATION:\n",
    "    PARTICLE_REPR_RANGES = ws_controller.get_optimized_layer_ranges(PARTICLE_REPR_RANGES, lam_test_inp, RANGE_OPTIMIZATION_TRESHOLD, \n",
    "        savefile=RANGE_OPTIMIZATION_FILE)\n",
    "\n",
    "for repr_range in PARTICLE_REPR_RANGES:\n",
    "    print(len(repr_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 1/20 (0) best fitness 3.331262482753833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39melif\u001b[39;00m TOP_REPR_SET_INDIV:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     pso\u001b[39m.\u001b[39mswarm[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mset_pos([\u001b[39mfloat\u001b[39m(\u001b[39mlen\u001b[39m(rng)) \u001b[39mfor\u001b[39;00m rng \u001b[39min\u001b[39;00m PARTICLE_REPR_RANGES])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pso\u001b[39m.\u001b[39;49mrun(NUM_ITERATIONS, logger_fc, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/../../utils/pso/pso.py:336\u001b[0m, in \u001b[0;36mPSOController.run\u001b[0;34m(self, time, logger_fc, save_data, limit_position, limit_velocity, verbose)\u001b[0m\n\u001b[1;32m    333\u001b[0m     particle\u001b[39m.\u001b[39mmove(best_particle\u001b[39m.\u001b[39mposition, limit_position, limit_velocity)\n\u001b[1;32m    335\u001b[0m \u001b[39m# ensure fitness update of the possibly detached best_particle\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_controller\u001b[39m.\u001b[39;49mcompute_fit([\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mswarm, best_particle], verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    338\u001b[0m \u001b[39m# this is here because of BH update - can happen that the particle with the\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39m# best my_best is reseted, but this link should be intact if it is still the \u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39m# best found swarm position\u001b[39;00m\n\u001b[1;32m    341\u001b[0m best_particle_candidat \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswarm, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39mmy_best\u001b[39m.\u001b[39mfitness)\u001b[39m.\u001b[39mmy_best\n",
      "File \u001b[0;32m~/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/../../utils/fitness_controller.py:100\u001b[0m, in \u001b[0;36mFitnessController.compute_fit\u001b[0;34m(self, individuals, verbose)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m# calculating the fitness data\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m individual \u001b[39min\u001b[39;00m individuals:\n\u001b[0;32m--> 100\u001b[0m     fit_vals\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_fit_vals(individual))\n\u001b[1;32m    102\u001b[0m \u001b[39m# updating the target\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_targs(fit_vals, verbose) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness_targ_update_fc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb Cell 16\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# share weigts by particle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m individual\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     individual\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m ws_controller\u001b[39m.\u001b[39;49mshare(individual\u001b[39m.\u001b[39;49mrepresentation, SHARE_ORDER, RETRAIN_AMOUNT, PREC_REDUCT, CLUST_MOD_FOCUS, CLUST_MOD_SPREAD, minibatch_kmeans\u001b[39m=\u001b[39;49mMINI_BATCH_KMEANS)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [individual\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], individual\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[0;32m~/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/../../utils/weight_sharing.py:459\u001b[0m, in \u001b[0;36mWeightShare.share\u001b[0;34m(self, layer_clusters, layer_order, retrain_amount, prec_reduct, mods_focus, mods_spread, verbose, n_clust_jobs, minibatch_kmeans)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     start_test \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()    \n\u001b[0;32m--> 459\u001b[0m     model_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest()\n\u001b[1;32m    460\u001b[0m     total_test \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_test\n\u001b[1;32m    462\u001b[0m compression_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression_rate()\n",
      "\u001b[1;32m/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb Cell 16\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lam_opt \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m mod : torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(mod\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lam_train \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m opt, epochs : train_net(model, criterion, opt, dataset, epochs, device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lam_test \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m : get_accuracy(model, dataset\u001b[39m.\u001b[39;49mtest_dl, DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ws_controller \u001b[39m=\u001b[39m WeightShare(model, lam_test, lam_opt, lam_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/coupekv/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/lenet_pso_compression.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ws_controller\u001b[39m.\u001b[39mset_reset()\n",
      "File \u001b[0;32m~/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/../../data/utils/mnist_utils.py:177\u001b[0m, in \u001b[0;36mget_accuracy\u001b[0;34m(net, data_loader, device)\u001b[0m\n\u001b[1;32m    173\u001b[0m     y_true \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_true)\n\u001b[1;32m    175\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 177\u001b[0m _, y_prob \u001b[39m=\u001b[39m net(X)\n\u001b[1;32m    178\u001b[0m _, predicted_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(y_prob, \u001b[39m1\u001b[39m)\n\u001b[1;32m    180\u001b[0m n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dokumenty/skola/MIT/DIP/code/notebooks/lenet_compression/../../models/lenet/lenet.py:49\u001b[0m, in \u001b[0;36mLeNet5.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     47\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquant(x)\n\u001b[0;32m---> 49\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor(x)\n\u001b[1;32m     51\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py:622\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 622\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mavg_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    623\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcount_include_pad, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdivisor_override)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_controll = FitnessController(TARGET, fitness_vals_fc, fit_from_vals, target_update_offset=TARGET_UPDATE_OFFSET, \n",
    "    lock=LOCK_TARGET, target_limit=TARGET_LOW_LIMIT)\n",
    "pso = PSOController(NUM_PARTICLES, PARTICLE_REPR_RANGES, PARTICLE_MAX_VELOCITY, INERTIA, fit_controll, \n",
    "    BH_radius=BH_RADUIUS, BH_vel_tresh=BH_VEL_TRESHOLD, BH_repr_rad=BH_REPR_RAD)\n",
    "\n",
    "if pso_data.size != 0:\n",
    "    pso.load_from_pd(pso_data, verbose=True)\n",
    "elif TOP_REPR_SET_INDIV:\n",
    "    pso.swarm[0].set_pos([float(len(rng)) for rng in PARTICLE_REPR_RANGES])\n",
    "\n",
    "pso.run(NUM_ITERATIONS, logger_fc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alcr(pso_data)\n",
    "plt.title('PSO algorithm on LeNet-5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
