{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search compression on LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREFIX = '../../'\n",
    "import sys\n",
    "sys.path.append(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from data.mnist import MnistDataset\n",
    "from data.utils.mnist_utils import *\n",
    "from models.lenet.lenet import LeNet5\n",
    "from utils.rnd import RandomController, Individual\n",
    "from utils.weight_sharing import *\n",
    "from utils.plot import *\n",
    "from utils.fitness_controller import FitnessController"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net train settings\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 10\n",
    "DEVICE = 'cpu'\n",
    "EPOCHS = 100\n",
    "\n",
    "# net save settings\n",
    "NET_TYPE = 'relu'\n",
    "NET_PATH = os.path.join(PATH_PREFIX, f'models/lenet/saves/lenet_{NET_TYPE}.save')\n",
    "\n",
    "# dataset settings\n",
    "DATA_PATH = os.path.join(PATH_PREFIX, 'data')\n",
    "\n",
    "# random search iter count\n",
    "NUM_INDIVIDUALS = 400\n",
    "\n",
    "# random search search settings\n",
    "REPR_RANGES = [range(1, 11) for _ in range(5)]\n",
    "\n",
    "# random search save settings\n",
    "SAVE_RND_FILE = os.path.join(PATH_PREFIX, 'results/test_RND_save.csv')\n",
    "SAVE_EVERY = 1\n",
    "\n",
    "# target position\n",
    "TARGET = [1.0, 12.0]\n",
    "TARGET_LOW_LIMIT = [0.95, 1.0]\n",
    "LOCK_TARGET = False\n",
    "TARGET_UPDATE_OFFSET = [0.001, 0.1]\n",
    "\n",
    "# WS settings\n",
    "SHARE_ORDER = [0, 1, 2, 3, 4]\n",
    "RETRAIN_AMOUNT = None #[0, 0, 0, 0, 0]\n",
    "PREC_REDUCT = 'f4'\n",
    "CLUST_MOD_FOCUS = None #[0, 0, 0, 0, 0]\n",
    "CLUST_MOD_SPREAD = None #[0, 0, 0, 0, 0]\n",
    "CLUST_ALG = 'kmeans'\n",
    "\n",
    "# range optimization settings\n",
    "RANGE_OPTIMIZATION = True\n",
    "RANGE_OPTIMIZATION_TRESHOLD = 0.97\n",
    "RANGE_OPTIMIZATION_FILE = os.path.join(PATH_PREFIX, f'models/lenet/saves/lenet_{NET_TYPE}_layer_perf_{PREC_REDUCT}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geting somewhat trained LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MnistDataset(BATCH_SIZE, DATA_PATH, val_split=0.5)\n",
    "model = LeNet5(N_CLASSES, NET_TYPE)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "train_settings = [criterion, optimizer, dataset, EPOCHS, DEVICE, 1, True]\n",
    "\n",
    "get_trained(model, NET_PATH, train_settings, DEVICE)\n",
    "\n",
    "before_loss = get_accuracy(model, dataset.test_dl, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting weight share controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_opt = lambda mod : torch.optim.Adam(mod.parameters(), lr=LEARNING_RATE)\n",
    "lam_train = lambda opt, epochs : train_net(model, criterion, opt, dataset, epochs, device=DEVICE)\n",
    "lam_test = lambda : get_accuracy(model, dataset.test_dl, DEVICE)\n",
    "\n",
    "ws_controller = WeightShare(model, lam_test, lam_opt, lam_train)\n",
    "ws_controller.set_reset()\n",
    "\n",
    "ws_controller.print_layers_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_vals_fc(individual:Individual):\n",
    "    # reset the net\n",
    "    ws_controller.reset()\n",
    "    \n",
    "    # share weigts by particle\n",
    "    if individual.data is None:\n",
    "        individual.data = ws_controller.share(individual.representation, SHARE_ORDER, \n",
    "            RETRAIN_AMOUNT, [PREC_REDUCT for _ in ws_controller.model_layers], CLUST_MOD_FOCUS, CLUST_MOD_SPREAD, clust_alg=CLUST_ALG)\n",
    "    \n",
    "    return [individual.data['accuracy'], individual.data['compression']]\n",
    "\n",
    "def fit_from_vals(data, targ_vals):\n",
    "\n",
    "    return 1 / math.sqrt(pow(1 - (data['accuracy']/targ_vals[0]), 2) + pow(1 - (data['compression']/targ_vals[1]), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'representation': [],\n",
    "    'accuracy': [],\n",
    "    'accuracy_loss': [],\n",
    "    'compression': [],\n",
    "    'share_t': [],\n",
    "    'train_t': [],\n",
    "    'acc_t': []\n",
    "}\n",
    "\n",
    "data_types = {\n",
    "    'accuracy': 'float32',\n",
    "    'accuracy_loss': 'float32',\n",
    "    'compression': 'float32',\n",
    "    'share_t': 'float32',\n",
    "    'train_t': 'float32',\n",
    "    'acc_t': 'float32'\n",
    "}\n",
    "\n",
    "rnd_data = pd.read_csv(SAVE_RND_FILE).astype(data_types) if os.path.exists(SAVE_RND_FILE) else pd.DataFrame(data).astype(data_types)\n",
    "\n",
    "def logger_fc(rnd_controler:RandomController):\n",
    "    global rnd_data\n",
    "\n",
    "    new_data = copy.deepcopy(data)\n",
    "\n",
    "    indiv = rnd_controler.current_indiv\n",
    "\n",
    "    new_data['representation'].append(indiv.representation)\n",
    "    new_data['accuracy'].append(indiv.data['accuracy'])\n",
    "    new_data['accuracy_loss'].append(before_loss - indiv.data['accuracy'])\n",
    "    new_data['compression'].append(indiv.data['compression'])\n",
    "    new_data['share_t'].append(indiv.data['times']['share'])\n",
    "    new_data['train_t'].append(indiv.data['times']['train'])\n",
    "    new_data['acc_t'].append(indiv.data['times']['test'])\n",
    "\n",
    "    # saving progress\n",
    "    rnd_data = rnd_data.append(pd.DataFrame(new_data).astype(data_types))\n",
    "    rnd_data.reset_index(drop=True, inplace=True)\n",
    "    os.makedirs(os.path.dirname(SAVE_RND_FILE), exist_ok=True)\n",
    "    rnd_data.to_csv(SAVE_RND_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting ranges with optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_test_inp = lambda _ : get_accuracy(model, dataset.test_dl, DEVICE)\n",
    "\n",
    "if RANGE_OPTIMIZATION:\n",
    "    REPR_RANGES = ws_controller.get_optimized_layer_ranges(REPR_RANGES, lam_test_inp, RANGE_OPTIMIZATION_TRESHOLD, \n",
    "        savefile=RANGE_OPTIMIZATION_FILE, prec_rtype=PREC_REDUCT, clust_alg=CLUST_ALG)\n",
    "\n",
    "for repr_range in REPR_RANGES:\n",
    "    print(len(repr_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_controll = FitnessController(TARGET, fitness_vals_fc, fit_from_vals, target_max_offset=TARGET_UPDATE_OFFSET, \n",
    "    lock=LOCK_TARGET, target_limit=TARGET_LOW_LIMIT)\n",
    "random = RandomController(REPR_RANGES, fit_controll)\n",
    "\n",
    "if rnd_data.size != 0:\n",
    "    random.load_from_pd(rnd_data, True)\n",
    "\n",
    "random.run(NUM_INDIVIDUALS, logger_fc, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alcr(rnd_data)\n",
    "plt.title('Random search on LeNet-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_controll.targ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
