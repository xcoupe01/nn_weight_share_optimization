{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO compression search on LeNet-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from data.mnist import MnistDataset\n",
    "from models.lenet.lenet import LeNet5\n",
    "from utils.train import *\n",
    "from utils.weight_sharing import *\n",
    "from utils.pso import PSOController\n",
    "from utils.plot import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net train settings\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 10\n",
    "DEVICE = 'cpu'\n",
    "EPOCHS = 100\n",
    "\n",
    "# net save settings\n",
    "NET_PATH = './models/lenet/saves/lenet_tanh.save'\n",
    "\n",
    "# pso iter count\n",
    "NUM_ITERATIONS = 20\n",
    "NUM_PARTICLES = 20\n",
    "\n",
    "# pso search settings\n",
    "PARTICLE_REPR_RANGES = [range(1, 51) for _ in range(5)]\n",
    "PARTICLE_MAX_VELOCITY = [4 for _ in range(5)]\n",
    "INERTIA = 0.8\n",
    "\n",
    "# pso save settings\n",
    "SAVE_PSO_FILE = './results/test_PSO_save.csv'\n",
    "SAVE_EVERY = 1\n",
    "\n",
    "# range optimization settings\n",
    "RANGE_OPTIMIZATION = True\n",
    "RANGE_OPTIMIZATION_TRESHOLD = 0.97\n",
    "RANGE_OPTIMIZATION_FILE = './results/lenet-tanh-layer-perf.csv'\n",
    "\n",
    "# WS settings\n",
    "SHARE_ORDER = [0, 1, 2, 3, 4]\n",
    "RETRAIN_AMOUNT = [0, 0, 0, 0, 0]\n",
    "PREC_REDUCT = None #['f4', 'f4', 'f4', 'f4', 'f4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geting somewhat trained LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MnistDataset(BATCH_SIZE, './data', val_split=0.5)\n",
    "model = LeNet5(N_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "train_settings = [criterion, optimizer, dataset, EPOCHS, DEVICE, 1, True]\n",
    "\n",
    "get_trained(model, NET_PATH, train_settings, DEVICE)\n",
    "\n",
    "before_loss = get_accuracy(model, dataset.test_dl, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_opt = lambda mod : torch.optim.Adam(mod.parameters(), lr=LEARNING_RATE)\n",
    "lam_train = lambda opt, epochs : train_net(model, criterion, opt, dataset, epochs, device=DEVICE)\n",
    "lam_test = lambda : get_accuracy(model, dataset.test_dl, DEVICE)\n",
    "\n",
    "ws_controller = WeightShare(model, lam_opt, lam_train, lam_test)\n",
    "\n",
    "ws_controller.print_layers_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_fc(particle):\n",
    "    # reset the net\n",
    "    get_trained(model, NET_PATH, train_settings, DEVICE)\n",
    "    ws_controller.reset()\n",
    "    \n",
    "    # share weigts by particle\n",
    "    particle.data = ws_controller.share(particle.representation, SHARE_ORDER, RETRAIN_AMOUNT, PREC_REDUCT, device=DEVICE)\n",
    "\n",
    "    # compute fitness\n",
    "    if particle.data['accuracy'] <= 0.95:\n",
    "        return particle.data['accuracy']\n",
    "\n",
    "    return 1 / math.sqrt(pow(1 - ((particle.data['accuracy'] - 0.9) * (1/0.1)), 2) + pow(1 - (particle.data['compression']/14), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define logging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'time': [],\n",
    "    'fitness': [],\n",
    "    'position': [],\n",
    "    'representation': [],\n",
    "    'velocity': [],\n",
    "    'accuracy': [],\n",
    "    'accuracy_loss': [],\n",
    "    'compression': [],\n",
    "    'share_t': [],\n",
    "    'train_t': [],\n",
    "    'acc_t': []\n",
    "}\n",
    "\n",
    "data_types = {\n",
    "    'time' : 'uint8',\n",
    "    'fitness': 'float32',\n",
    "    'accuracy': 'float32',\n",
    "    'accuracy_loss': 'float32',\n",
    "    'compression': 'float32',\n",
    "    'share_t': 'float32',\n",
    "    'train_t': 'float32',\n",
    "    'acc_t': 'float32'\n",
    "}\n",
    "\n",
    "pso_data = pd.read_csv(SAVE_PSO_FILE).astype(data_types) if os.path.exists(SAVE_PSO_FILE) else pd.DataFrame(data).astype(data_types)\n",
    "\n",
    "def logger_fc(pso_cont:PSOController):\n",
    "    global pso_data\n",
    "\n",
    "    new_data = copy.deepcopy(data)\n",
    "\n",
    "    for particle in pso_cont.swarm:\n",
    "\n",
    "        new_data['time'].append(pso_cont.time)\n",
    "        new_data['fitness'].append(particle.current_fit)\n",
    "        new_data['position'].append(particle.position)\n",
    "        new_data['representation'].append(particle.representation)\n",
    "        new_data['velocity'].append(particle.velocity)\n",
    "        new_data['accuracy'].append(particle.data['accuracy'])\n",
    "        new_data['accuracy_loss'].append(before_loss - particle.data['accuracy'])\n",
    "        new_data['compression'].append(particle.data['compression'])\n",
    "        new_data['share_t'].append(particle.data['times']['share'])\n",
    "        new_data['train_t'].append(particle.data['times']['train'])\n",
    "        new_data['acc_t'].append(particle.data['times']['test'])\n",
    "\n",
    "    # saving progress\n",
    "    pso_data = pso_data.append(pd.DataFrame(new_data).astype(data_types))\n",
    "    if pso_cont.time % SAVE_EVERY == SAVE_EVERY - 1:\n",
    "        pso_data.reset_index(drop=True, inplace=True)\n",
    "        os.makedirs(os.path.dirname(SAVE_PSO_FILE), exist_ok=True)\n",
    "        pso_data.to_csv(SAVE_PSO_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_test_inp = lambda _ : get_accuracy(model, dataset.test_dl, DEVICE)\n",
    "\n",
    "if RANGE_OPTIMIZATION:\n",
    "    PARTICLE_REPR_RANGES = ws_controller.get_optimized_layer_ranges(PARTICLE_REPR_RANGES, lam_test_inp, RANGE_OPTIMIZATION_TRESHOLD, \n",
    "        savefile=RANGE_OPTIMIZATION_FILE)\n",
    "\n",
    "for repr_range in PARTICLE_REPR_RANGES:\n",
    "    print(len(repr_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSOController(NUM_PARTICLES, PARTICLE_REPR_RANGES, PARTICLE_MAX_VELOCITY, fitness_fc, INERTIA)\n",
    "\n",
    "if pso_data.size != 0:\n",
    "    pso.load_from_pd(pso_data)\n",
    "\n",
    "pso.run(NUM_ITERATIONS, logger_fc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alcr(pso_data)\n",
    "plt.title('PSO algorithm on LeNet-5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 20 2022, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
