{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data.mnist import MnistDataset\n",
    "from models.lenet.lenet import LeNet5\n",
    "from utils.train import *\n",
    "from utils.quantize import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 10\n",
    "DEVICE = None\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MnistDataset(BATCH_SIZE, './data')\n",
    "model = LeNet5(N_CLASSES)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:42:35 --- Epoch: 1\tTrain loss: 0.6829\tValid loss: 0.3322\tTrain accuracy: 89.85\tValid accuracy: 90.54\n",
      "22:43:46 --- Epoch: 2\tTrain loss: 0.3006\tValid loss: 0.2515\tTrain accuracy: 92.05\tValid accuracy: 92.70\n",
      "22:44:58 --- Epoch: 3\tTrain loss: 0.2316\tValid loss: 0.1928\tTrain accuracy: 93.77\tValid accuracy: 94.13\n",
      "22:46:18 --- Epoch: 4\tTrain loss: 0.1879\tValid loss: 0.1664\tTrain accuracy: 94.48\tValid accuracy: 94.83\n",
      "22:47:44 --- Epoch: 5\tTrain loss: 0.1562\tValid loss: 0.1501\tTrain accuracy: 95.24\tValid accuracy: 95.27\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAEyCAYAAADqTulnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABLKElEQVR4nO3deVxU9f7H8des7AIqjKJImbjjUi5o5gIqbqhdtb1stbz9ylJLs7TcW8zU22LeTMuyblZuadsFlXI3Na6muYWiLJq4gcJs5/fHwCCyiDrDLHyej4cPZebMme+HM857vt853+9RKYqiIIQQQgiPo3Z1A4QQQghxfSTEhRBCCA8lIS6EEEJ4KAlxIYQQwkNJiAshhBAeSkJcCCGE8FAS4kIIj7Z161a6du3q6mYI4RIS4kI4UVxcHJs2bXJ1M4QQXkpCXAhxXcxms6ubIES1JyEuhAsYjUamT59Oly5d6NKlC9OnT8doNAKQk5PDk08+Sbt27ejQoQP33XcfVqsVgAULFnDHHXfQtm1bEhIS2Lx5c5n7v3DhAi+++CKxsbH06NGD999/H6vVitFopF27dhw4cMC+bU5ODq1ateL06dMArFu3jkGDBtGuXTvuuece9u/fb982Li6OBQsWkJiYSJs2bcoM8sOHD/PII4/QoUMHEhISWLt2rf2+8ePHM2nSJB555BHatm3LAw88wIkTJ+z379y5kyFDhnDbbbcxZMgQdu7cab/v7NmzvPTSS3Tp0oX27dvzz3/+s8Tzfvzxx3Tq1IkuXbrwzTff2G/fsGED/fr1o23bttxxxx0sXLjw6gdICE+hCCGcpkePHsrGjRtL3T5nzhxl2LBhyt9//62cPn1aufvuu5V33nlHURRFmTVrljJx4kTFaDQqRqNR2b59u2K1WpXDhw8rXbt2VbKyshRFUZT09HTl6NGjZT7vCy+8oDz11FPKhQsXlPT0dKV3797KV199pSiKoowfP16ZPXu2fdvPPvtMefTRRxVFUZS9e/cqsbGxyu7duxWz2ax8++23So8ePZSCggJ7PQMHDlQyMjKUS5culXrevLw8pWvXrsrXX3+tmEwmZe/evUqHDh2UgwcPKoqiKOPGjVPatGmjbNu2TSkoKFCmTp2q3HPPPYqiKMqZM2eUdu3aKcuXL1dMJpOyevVqpV27dkpOTo6iKIryxBNPKKNGjVLOnj2rGI1GZevWrYqiKMqWLVuUZs2aKXPmzFGMRqOyfv16pVWrVsrZs2cVRVGU22+/Xdm+fbuiKIpy9uxZZc+ePZU9fEK4PemJC+ECq1ev5umnn6ZWrVrUrFmTp59+mlWrVgGg1Wo5deoUGRkZ6HQ62rVrh0qlQqPRYDQaOXz4MCaTifr169OgQYNS+7ZYLKxdu5YxY8YQGBhI/fr1eeSRR+z7T0xMZM2aNSXakpiYCMB//vMf7r77blq3bo1Go+HOO+9Ep9Oxe/du+/YPPvggdevWxdfXt9Rzr1+/nnr16jFkyBC0Wi3NmzcnISGBH374wb5N9+7dad++PXq9nueff57du3eTmZnJ+vXriYqKYvDgwWi1WgYMGEDDhg1Zt24dJ0+eJCUlhcmTJxMcHIxOp6NDhw72fWq1Wp5++ml0Oh3dunXD39+fv/76y37foUOHyM3NJTg4mBYtWtzAkRPCvUiIC+ECJ0+eJCIiwv5zREQEJ0+eBOCxxx4jKiqKRx99lPj4eBYsWABAVFQUEyZM4F//+hedO3fm+eefJzs7u9S+z5w5g8lkKrX/om07duxIfn4+v//+O8ePH2f//v307NkTgIyMDBYtWkS7du3sf7KysuxtA6hbt265dZ04cYLU1NQSj1+9ejWnTp2yb1OnTh37vwMCAggODubkyZOlfieXtzsrK4vg4GCCg4PLfN6QkBC0Wq39Zz8/Py5evAjAvHnz2LBhAz169OCBBx5g165d5bZfCE+jvfomQghHCw8PJyMjg+joaAAyMzMJDw8HIDAwkPHjxzN+/HgOHDjA8OHDiYmJoVOnTiQmJpKYmEhubi6TJk1i1qxZvPXWWyX2HRoaik6nIyMjg0aNGtn3bzAYANBoNPTp04fvvvuO2rVr0717dwIDAwFbQD/11FOMHDmy3LarVKpy76tbty7t27dn0aJF5W6TlZVl/3deXh7nzp0jPDzc/ju5XGZmJnfccQd16tTh3LlznD9/nho1apS777K0atWKDz74AJPJxOeff85zzz3Hhg0brmkfQrgr6YkL4WQmk4mCggL7H7PZTP/+/fnggw/IyckhJyeH9957zz6kvW7dOo4ePYqiKAQFBaHRaFCpVBw5coTNmzdjNBrR6/X4+PigVpf+L1wU0u+88w65ubmcOHGCRYsWMXDgQPs2iYmJfP/996xevZoBAwbYbx82bBhffvklv//+O4qicPHiRdavX09ubm6lau3evTtpaWmsWLECk8mEyWQiNTWVw4cP27fZsGEDO3bswGg0MnfuXFq3bk3dunXp1q0baWlprF69GrPZzNq1azl06BDdu3cnPDycrl27MnnyZM6dO4fJZGL79u1XbY/RaGTVqlVcuHABnU5HQEBAmb8zITyV9MSFcLIRI0aU+Pmpp57in//8J3l5efZg7dOnj/1s66NHjzJ16lRycnKoUaMG9957L7Gxsezfv5+3336bw4cPo9PpaNu2LVOmTCnzOSdOnMjUqVPp2bMnPj4+DBs2jCFDhtjvb926NX5+fpw8ebLEQikxMTFMnTqVKVOmcPToUXx9fbn11ltp165dpWoNDAxk4cKFvP7667z++usoikKTJk146aWX7NsMGDCA9957j927d9O8eXP7SEJoaCjz589nxowZvPbaa0RFRTF//nxq1qwJwJtvvsnMmTPp27cvJpOJjh070r59+6u2aeXKlUydOhWLxcLNN99cauRCCE+mUhRFcXUjhBDVw/jx4zEYDDz//POubooQXkHGlYQQQggPJSEuhBBCeCgZThdCCCE8lPTEhRBCCA8lIS6EEEJ4KKdOMUtJSWH69OlYrVaGDRtWaqrNjBkz2Lp1KwD5+fmcPn2aHTt2VLjPU6cuOLSNoaH+nDlz0aH7dBWpxT15Sy3eUgdILe7IW+oAx9cSFhZU7n1OC3GLxcKUKVNYtGgRBoOBoUOHEhcXZ19BCmDChAn2fy9ZsoQ//vjDWc0pl1arqfLndBapxT15Sy3eUgdILe7IW+qAqq3FacPpqampREVFERkZiV6vp3///iQlJZW7/Zo1a0qsHCWEEEKIijktxLOzs0tc6MBgMJR5sQawXTTh+PHjxMbGOqs5QgghhNdxi2VX16xZQ0JCAhrN1YcgQkP9HT5UUdH3DZ5GanFP3lKLt9QBUos78pY6oOpqcVqIGwyGElcrys7Otl9F6Upr165l0qRJldqvo098CAsLcvjJcq4itbgnb6nFW+oAqcUdeUsd4PhaKvpA4LTh9JiYGNLS0khPT8doNLJmzRri4uJKbXf48GHOnz9P27ZtndUUIYQQwis5rSeu1WqZNGkSjz/+OBaLhSFDhhAdHc3cuXNp2bIl8fHxgK0X3q9fvwqvUSyEEEKI0pz6nXi3bt3o1q1bidtGjRpV4udnnnnGmU0QQgghvJZbnNgmhBDCO507d5ZRo/4JQE7OadRqNSEhoQD8+9+foNPpyn3s/v1/8MMPa3juuRcqfI6nnnqU+fM/vuG27ty5gy+//Iw335xzw/uqKtU6xI8fV7FoEdx7L/j6uro1QgjhfYKDQ1i8eCkACxd+iJ+fP/fd96D9frPZjFZbdhQ1bdqcpk2bX/U5HBHgnqpah3hSkpZx4+D4cT0TJxpd3RwhhKgWpk9/Db1ez4EDf9KqVWvi43vz/vtzyMu7iI+PLxMmTKJBg5tK9IwXLvyQ7OwsMjJOkJ2dzV133cuwYfcA0KvXHfz88y/s3LmDjz9eQEhICEeOHKZJk2ZMmjQVlUrF5s2/8q9/vYOvrx+tWrUmI+NEhT3u8+fPMXPmFDIyTuDj48uLL75Mo0bR7Nr1G3Pnvg2ASgXvvfdvLl68xKuvvkReXh4Wi5lp06YSFdWkKn6V1TvEhw418d57vrz/vp7Bg83ExFhd3SQhhKgWTp06yfz5H6PRaMjLy+Xzzz/nzJlLbN++lQ8/fI/p098q9Zhjx44yb958Ll68yH33DeHOO4eW6sUfPPgnS5Z8Re3aYYwc+Ripqb/TtGkz3nprJu++u4CIiHq8+uqEUvu+0sKFHxId3YSZM9/mt9+2M23aqyxevJQvvviM0aNfpFWrNly8eBG9Xs/Klcvp0CGW4cMfw2KxEBio5dKlqrnKd7UO8YAA+PBDSEhQMWaML99/f5FKrDcjhBAe6bXXfFi92rFv+4mJZl57reCaH9ejR0/7Al+5ubmMGjWNw4ePoFKpMJvNZT6mU6fb0ev16PV6QkNDyck5TXh4yfVHmjVrYb8tOroxWVkZ+Pv7ERFRj4iIegD06pXAqlXLK2xfaupupk17E4DbbmvP+fPnyMvLJSamNf/61zv07t2Xbt16EB5uoFmz5sycOQWz2UzXrt3p3Lkdly5VzZz3an8p0t69bT3y3bs1/Pvf5Z9gIYQQwnF8LzsR6aOP5tOxY0eWLPmKN954B6Ox7K83dTq9/d9qtRqLxVJqG73+6tvciAcffJjx4ydSUJDPyJGPcfRoGm3a3Mp77/2bsLBwpk+fzIoVKxz6nBWp1j3xIlOmFJCcrOH1133o189MgwZVMwwihBBV6bXXCq6r1+xsubm59hU9165d7fD9N2gQRUbGCTIzM6hbN4KkpJ+v+pjWrdvy888/8PDDj7Nz5w6Cg4MJCAjkxInj3HJLI265pRH79//B0aNp+Pj4EBYWzsCBd2IyGdm7dy+33x7v8DrKIiEO1K6tMHlyAc8848e4cb4sXXoJWXtGCCGqxv33P8Trr09Bp3uXTp26OHz/Pj6+jB49jjFjnsHX149mza5+xvujj45g5swpDB9+Dz4+vrz88mQAvvpqKTt37kCtVnPTTQ2Jje1MUtJPLF36KVqtFj8/f2bPnuXwGsqjUhTFo7qdjl5bt2iNW0WBu+7yY8MGLfPnX+If/yj7Oxl3JmsPuydvqcVb6gCpxR05u46LFy/i7++Poii8/fYbREZGcvfd9zvlubxi7XRPo1LBW2/l4+en8MorPuTkuLpFQgghHGX16uU8/PB9PPjgXeTl5TJo0BBXN8khZDj9MjfdpDB2rJGpU32YPNmXuXPzXd0kIYQQDnD33fc7reftStITv8LIkUZatrTwxRc6fvlF5psJIYRwXxLiV9Bq4Z138lGrFcaM8eXSJVe3SAghhCibhHgZWre2MmKEibQ0NW+/rb/6A4QQQggXkBAvx7hxBURGWnnvPT1798qvSQghhPuRdCpHQIDtbHWLRcXo0b44eNEfIYSoFp555km2bt1c4ravvlrKrFkzy33M//3fCPbv/wOAsWOf5cKF0tO1Fi78kKVLl1T43Ckp6/nrryP2nz/6aD7bt2+9luaXaefOHbz44nM3vB9HkBCvQFychX/8w8SuXRoWLpQlWYUQ4lr17JlAUtJPJW77739/omfPhEo9ftaseQQFlT9PuiK//LKetLTiEH/88ado377jde3LXckUs6uYOrWAdeu0zJjhQ9++ZiIjPWptHCGEcKkePeL5978/wGQyodPpyMzM4O+/T9G6dVtmzZrJvn1/UFBQQP/+fbn33kdKPX7o0EQ++mgJISEhfPLJQr7/fg2hoaGEhxto0qQZAKtWLWfVquWYTCbq16/PxIlTOXjwT379NYXdu3fyyScfM336myxe/BGdO3ehR4+e7Nixjffem4PFYqFp0+aMHfsSer2eoUMT6dt3ABs3pmA2m5k69Q2iom4qt76yLlkaFnZrpS5ZOnbsS7Ru3faGfr/SE7+KsDCFyZPzuXhRxbhxvnjW+nZCCOFaNWoE07x5C7Zs2QjYeuFxcb1QqVSMGPFPFi5cwieffMH27ds5dOhgufvZv38fSUk/sXjxUmbNmmsfbgfo1q0HH330KZ988gVRUTfz3XcriIlpTZcuXfnnP59l8eKl1KtX3759QUEBM2ZMZvLkmXz66X+wWCysWPG1/f7g4GA+/vhzBg8eyhdfVDxkX3TJ0k8++ZInn3yaadNeBbBfsnTx4qW8995H6PU+/PzzD3ToEMvixUtZvPgLoqMbX9fv9HLSE6+Eu+82s2yZmf/+V8vKlVoGD/a8JVmFECLgtVfwWb3CofssSBxM3mvTKtymZ88E/vvfn7jjju4kJf3E+PETAUhO/plVq5ZjsVjIyTlNWtoRGjWKLnMfqam76Nq1h/3qZ126dLXfd+TIYf797w/Izb3ApUuX6NAhtsL2HDt2lLp1I2jQIAqAvn0H8O23y7jrrvsA6NYtDoAmTZqxYcO6CvdV1iVLc3Mrd8nS6OgmFe67MqQnXglFS7L6+ipMmODDmTOubpEQQniOLl268dtv2/nzz/3k5+fTtGkzMjJO8MUXnzFnzgd88smXdO/evdxLkF7NjBmTef75F/n00//wyCNPXPd+ihRd8lSjUWOxXF+nrTKXLP3+++9uqJ0gPfFKa9jQtiTrtGk+TJ7sw5w57nc5PyGEqEjea9Ou2mt2Bn9/f269tR0zZ06hVy/bCW15eXn4+voRGBhITs5pUlJSaNasVbn7aN36VmbMeI0HH3wYi8XCxo2/MHDgPwC4eDGP2rVrYzab+emn7wkLC7c/78WLF0vtq0GDKDIzMzh+PJ369SP58ce1tGlz63XVVtYlSwMDAzl0aN9VL1l64MCf9O074Lqet4iE+DUYOdLI8uVali7VM3SomS5dZN6ZEEJURs+eCUyYMJbJk2cAEB3dmMaNm3DffUMxGAzcemvFIdqkSVPi4noxfPh9hIaG0rRp8eVEH398JCNGPExISAjNm7e0B3d8fG/efHM6X3/9pX3IG8DHx4cJE15l4sRx9hPbBg++vgui3MglS195ZfJ1Pefl5FKk13jJuF271PTt609UlML69Xn4+Tm0OTfEWy5JCFKLO/KWOkBqcUfeUgfIpUjdWtu2Vp54wsRff6l55x1ZklUIIYTrSIhfh6IlWd99V5ZkFUII4TqSQNchMBDefDMfs1nFmDGyJKsQQgjXkBC/TvHxtiVZd+7UsGiRLMkqhBCi6kmI34ApUwoICVGYPt2HEydUrm6OEEKIakZC/AaEh9uWZM3LkyVZhRBCVD0J8Rt0zz1m7rjDzE8/aVm1SqbdCyGEqDoS4jfoyiVZz551dYuEEEJUFxLiDtCwocKYMUZOnVIzZYqPq5sjhBCimnBqiKekpJCQkECvXr1YsGBBmdusXbuWfv360b9/f8aMGePM5jjVP/9ppHlzC599pmfTJo2rmyOEEKIacNqXuBaLhSlTprBo0SIMBgNDhw4lLi6ORo0a2bdJS0tjwYIFfPHFFwQHB3P69GlnNcfpdDqYPTufvn39GTPGl3Xr8ii8Yp4QQgjhFE7riaemphIVFUVkZCR6vZ7+/fuTlJRUYpuvvvqK+++/n+DgYABq1arlrOZUiVtvtS3JeviwLMkqhBDC+ZwW4tnZ2dSpU8f+s8FgIDs7u8Q2aWlp/PXXX9xzzz3cddddpKSkOKs5VWb8+ALq17fyr3/p2bdPTjkQQgjhPC6dE2WxWDh69ChLliwhKyuLBx54gNWrV1OjRo1yHxMa6o9W69jvnCu6Qsy17wvmz4cBA2DcuAB+/RU0VfgVuSNrcTWpxf14Sx0gtbgjb6kDqq4Wp4W4wWAgKyvL/nN2djYGg6HUNq1bt0an0xEZGclNN91EWloarVqVf2H4M2dKX+D9Rjjj8ncdOsDgwb6sWKHjrbfyeewxk0P3Xx65lJ978pZavKUOkFrckbfUAV5yKdKYmBjS0tJIT0/HaDSyZs0a4uLiSmzTs2dPtm3bBkBOTg5paWlERkY6q0lVato025Ks06bJkqxCCCGcw2khrtVqmTRpEo8//jj9+vWjb9++REdHM3fuXPsJbnfccQchISH069eP4cOH8+KLLxIaGuqsJlWp8HCF116zLck6frwsySqEEMLxVIriWfHi6OEWZw7hKAr84x9+bNyoZeHCSyQmmp3yPEVkOMo9eUst3lIHSC3uyFvqAC8ZThe2JVnffjsfHx+Fl16SJVmFEEI4loS4kxUtyXrypJqpU2VJViGEEI4jIV4Fnn7aSLNmFpYskSVZhRBCOI6EeBUoWpJVpVIYO9aH/HxXt0gIIYQ3kBCvIrfdZuWxx0wcOqRhzhxZklUIIcSNkxCvQhMmFFCvnm1J1v375VcvhBDixkiSVKHAQHjjjXxMJhWjR/titbq6RUIIITyZhHgV693bwqBBJnbs0LB4sc7VzRFCCOHBJMRdYNq0AoKDbUuyZmTIkqxCCCGuj4S4CxgMCq++WkBurorx431kSVYhhBDXRULcRe6/30TnzmZ++EHHd9+59IqwQgghPJSEuItcviTrhAk+nDvn6hYJIYTwNBLiLnTLLQrPP28kO1uWZBVCCHHtJMRd7P/+z7Yk66ef6tmyRZZkFUIIUXkS4i6m19uG1VUqhTFjfCgocHWLhBBCeAoJcTfQrp2VRx81cfCgLMkqhBCi8iTE3cTLLxcQEWFl3jw9f/4ph0UIIcTVSVq4icBAeP11WZJVCCFE5UmIu5E+fSwkJprYvl3DJ5/IkqxCCCEqJiHuZmbMKKBGDYWpU33IzJQlWYUQQpRPQtzNXL4k60svydxxIYQQ5ZMQd0P3328iNtbM2rU61qyRJVmFEEKUTULcDanV8PbbBej1CuPH+3D+vKtbJIQQwh1JiLup6GirLMkqhBCiQhLibuyZZ4w0bWrhk09kSVYhhBClSYi7scuXZB07VpZkFUIIUZKEuJtr397Kww+bOHBAw7x5siSrEEKIYhLiHuCVVwqoW9fK3Ll6DhyQQyaEEMJGEsEDBAXB668XYDSqGD3aR5ZkFUIIAUiIe4y+fc0MGGBi2zYtS5bIkqxCCCEkxD1K0ZKsU6b4kJUlS7IKIUR1JyHuQerUUZg4sYALF2RJViGEEBLiHufBB21Lsq5Zo2PtWlmSVQghqjOnhnhKSgoJCQn06tWLBQsWlLr/22+/JTY2lkGDBjFo0CCWLVvmzOZ4hSuXZL1wwdUtEkII4SpOC3GLxcKUKVP46KOPWLNmDd999x2HDh0qtV2/fv1YuXIlK1euZNiwYc5qjleJjrby3HNGsrLUTJsmw+pCCFFdOS3EU1NTiYqKIjIyEr1eT//+/UlKSnLW01U7zzxjpHFjC4sX69i2Tb4VEUKI6shp7/7Z2dnUqVPH/rPBYCA7O7vUdj/99BOJiYk8++yzZGZmOqs5XsfHxzasrigqxozxlSVZhRCiGnLpmVE9evRgwIAB6PV6vvzyS8aNG8enn35a4WNCQ/3Rah17MZCwsCCH7q+qDBgAI0fCBx9oWLQoiIkTPbeWskgt7sdb6gCpxR15Sx1QdbU4LcQNBgNZWVn2n7OzszEYDCW2CQ0Ntf972LBhvPXWW1fd75kzFx3XSGy/6FOnPPfssDFjYPnyAKZNUzFsmIpatTy3lst5+nG5nLfU4i11gNTijrylDnB8LRV9IHDacHpMTAxpaWmkp6djNBpZs2YNcXFxJbY5efKk/d/JycnccsstzmqO16pRA2bOtC3JOmIEsiSrEEJUI07riWu1WiZNmsTjjz+OxWJhyJAhREdHM3fuXFq2bEl8fDxLliwhOTkZjUZDcHAwM2fOdFZzvFr//mb69TOxdq2Ozz7T8dBDJlc3SQghRBVQKYqiuLoR18LRwy3eMoSTlaWiS5dAQGHjxjwMBo86rKV4y3EB76nFW+oAqcUdeUsd4CXD6aJq1amj8MYbcP68igkTZO64EEJUBxLiXmTECOjQwczq1Tp++MGxZ/ALIYRwPxLiXqRoSVadTmHcOF9ZklUIIbychLiXadLEyqhRRjIz1UyfLsPqQgjhzSTEvdCoUbYlWRct0rF9uxxiIYTwVvIO74V8fGDWrOIlWY1GV7dICCGEM0iIe6nYWAsPPWRk/34N776rd3VzhBBCOIGEuBebNKkAg8HK7Nl6Dh1Subo5QgghHExC3ItdviTrmDG+siSrEEJ4GQlxLzdggJm+fU1s3qxl6VKdq5sjhBDCgSTEq4HXXy8gMFBh8mQfsrNlWF0IIbyFhHg1ULeuwiuvFHDunIqXX5a540II4S0kxKuJhx820b69hVWrdPz4oyzJKoQQ3kBCvJpQq2H27Hz7kqy5ua5ukRBCiBslIV6NNGli5dlnjWRkqJkxQ4bVhRDC00mIVzOjRhlp1MjCwoU6duyQwy+EEJ5M3sWrGV9fmD1blmQVQghvICFeDcXGWnjwQSP79ml4/31ZklUIITyVhHg1NWlSAeHhVt5+W8/hwzJ3XAghPJGEeDUVHGxbkrWgQMXYsb4oiqtbJIQQ4lpJiFdjAwaY6dPHxMaNsiSrEEJ4okqF+F9//UVBQQEAv/zyCwsWLODcuXNObZhwPpWqeEnW117z4eRJGVYXQghPUqkQf+6551Cr1aSnp/Pqq6+Snp7OuHHjnN02UQUiIhReftm2JOsrr8jccSGE8CSVCnG1Wo1Op2PDhg3ce++9TJ06lczMTGe3TVSRRx4x0a6dhRUrdPz8syzJKoQQnqJSIV5QUMDff//NunXriI2NBUCRM6G8hloNb79tW5L1xRdlSVYhhPAUlQrx4cOH06dPH/z9/YmJiSE9PZ2goCBnt01UoWbNrDzzjJETJ9S8/roMqwshhCdQKdfRpbZarZjNZvT6ql8o5NSpCw7dX1hYkMP36So3Wkt+PsTF+XP4sJrvv7/IrbdaHdi6ayPHxf14Sx0gtbgjb6kDHF9LWFj5neZK9cTXrl1LbuEY65w5c3jiiSc4ePCgY1on3IavL8yaZVuS9fnnfTGZXN0iIYQQFalUiH/wwQcEBgaSmprKxo0bGTx4MFOnTnV224QLdO5s4YEHZElWIYTwBJUKca1WC8DGjRsZNmwYiYmJ9nnjwvtMmlRAWJiVWbP0HDkic8eFEMJdVSrEVSoVa9euZe3atXTq1AkAk4y1eq2QEFmSVQghPEGlQnzixIl89913DB06lMjISNLS0ujYsaOz2yZcKDHRTEKCmV9/1fLll1pXN0cIIUQZKhXibdu25f3332f48OEA3HTTTUycOPGqj0tJSSEhIYFevXqxYMGCcrf78ccfadKkCf/73/8q2WzhbLYlWfMJCFB49VVfWZJVCCHcUKVCPCcnh9GjRxMbG0tsbCxjxowhJyenwsdYLBamTJnCRx99xJo1a/juu+84dOhQqe1yc3P59NNPad269fVVIJymXj3bkqxnz6qYOFHmjgshhLupVIi/+uqrREVFsXLlSlauXElUVBSTJk2q8DGpqalERUURGRmJXq+nf//+JCUlldpu7ty5PPHEE/j4SEi4o0ceMXHbbRaWL9fx3//KkqxCCOFOKhXix44dY9SoURgMBgwGA88++yzp6ekVPiY7O5s6derYfzYYDGRnZ5fYZu/evWRlZdG9e/drb7moEhqNbUlWrVaWZBVCCHdTqTOWrFYrp0+fplatWgCcPn0aq/XGVvOyWq28/vrrzJw585oeFxrqj1br2B5hRavheBpn1NKtG4wbB9Onq5g3L4h33nH4U5RJjov78ZY6QGpxR95SB1RdLZUK8ccee4zBgwfbe8wbNmxg9OjRFT7GYDCQlZVl/zk7OxuDwWD/OS8vjwMHDvDQQw8BcOrUKUaOHMkHH3xATExMufs9c+ZiZZpcabLUX+U8+SR88UUA8+ap6Nv3Im3bOndJVjku7sdb6gCpxR15Sx3ghsuuDh48mI8//pgmTZrQpEkTPvroI+bMmVPhY2JiYkhLSyM9PR2j0ciaNWuIi4uz3x8UFMTWrVtJTk4mOTmZNm3aXDXAhev4+tqG1a1WFaNHy5KsQgjhDio9ATg6Opro6Gj7z1e7bopWq2XSpEk8/vjjWCwWhgwZQnR0NHPnzqVly5bEx8dff6uFS9x+u4X77zfy+ed6PvhAz7PPGl3dJCGEqNauexUPlerq84a7detGt27dStw2atSoMrddsmTJ9TZFVKFXXy3gp5+0zJqlZ8AAEw0bynJuQgjhKhWGeFnzuouYzWaHN0a4v5AQmD69gBEj/HjhBV++/voSlfg8J4QQwgkqDPERI0aUe5/M666+Bg0ys2yZmZ9/1vKf/2i55x75QCeEEK5QYYgnJydXVTuEB1Gp4I038tm0KYBXX/UlPj6PsDAZVhdCiKpWqbPThbhS/foKEyYUcOaMLMkqhBCuIiEurtujj5q49VYL336rIylJlmQVQoiqJiEurpssySqEEK4lIS5uSIsWVp5+2kh6upo335RhdSGEqEoS4uKGjR5t5OabrSxYoGP3bnlJCSFEVZF3XHHD/PxkSVYhhHAFCXHhEF26WLj3XhN79miYP1/v6uYIIUS1ICEuHOa11/KpXdvKrFl6/vpLlnETQghnkxAXDhMaaluS9dIlFS+84MtVrpEjhBDiBkmIC4caPNhMz55mUlK0fPXVdV9fRwghRCVIiAuHKlqS1d9f4dVXffj7bxlWF0IIZ5EQFw4XGanw0ksF5OSoZUlWIYRwIglx4RSPP26ibVsL33yjIzlZlmQVQghnkBAXTlG0JKtGY1uSNS/P1S0SQgjvIyEunKZlS9uSrMeOyZKsQgjhDBLiwqnGjDFy001WPvxQx++/y8tNCCEcSd5VhVP5+cGsWcVLsprNrm6REEJ4Dwlx4XRdu1q45x4T//ufhg8/1Lm6OUII4TUkxEWVKFqS9c03fUhLk7njQgjhCNU7xC0WOHQIrFZXt8Tr1awJU6fKkqxCCOFI1TrEfb/4DKKjqXlrCwImjke7basEuhP94x9m4uLMbNig5euvZUlWIYS4UdU6xI29EmD4cFS5ufh/+D6hA3rZAv2VcWi3bpFAdzCVCt5807Yk66RJPpw+LcPqQghxI6p1iFsNdWDxYk7/cZhzS5eRf8/9qPLy8F/wAaGJvanZtjkBL7+IdstmCXQHadBAYfz4Ak6fVjNpkswdF0KIG1GtQ9xOr8fYM4EL8z7g9N5DnPviay7d+wCqSxfx//d8QgcmULNNMwImvIBuyyYJ9Bv0xBMm2rSxsGyZjnXrZElWIYS4XhLiV9LrMcb3Jnfu+5zec4izX37DpfseRFWQj/9HHxIysA81Wzcl8KWx6DZvtJ0cJ67J5UuyvvCCLMkqhBDXS0K8Ino9prhe5M55rzDQv+XS/Q+hMhbgt3ABIYP62gJ9/Bh0m36VQL8GMTFWRo60Lck6a5YMqwshxPWQEK8snQ5TXE9y33nXFuj/Wc6lB4ajMpvw+/jfhAzuZwv0caPRbfxFAr0Sxo41EhVlZf58Hf/7n7wUhRDiWsk75/XQ6TD1iCd39r84/b+DnP1qBZcefBiVxYzfoo8IubM/tVo1IfDF59H9miKBXg5/f9uSrBaLiueflyVZhRDiWkmI3yidDlP3OHLfnmcL9GUrufTgI2C14Ld4ISH/GECtmMYEvvA8ul82IElVUrduFu66y0RqqoYFC2RJViGEuBYS4o6k1WLq1oPct+faAv3rVVx66FFAwe+ThYQMSaRWq8YEjn0OXcp6CfRCkycXUKuWbUnWo0dl7rgQQlSWU0M8JSWFhIQEevXqxYIFC0rd/8UXX5CYmMigQYO49957OXTokDObU7W0Wkxdu5M7aw6nUw9w9pvVXBr+GKDC79OPCRk6kFox0QSOGYVuw7pqHei1ailMnVrAxYsqXnxRlmQVQojKUimKc94yLRYLCQkJLFq0CIPBwNChQ5k9ezaNGjWyb5Obm0tgYCAASUlJLF26lIULF1a431OnLji0nWFhQQ7fZ4UsFnSbN+Kzajk+a1ajPnUSAGutWhT0S6QgcTCmLl1Be+3LklZ5LQ6kKHDPPX6sW6fl/fcvMXKkn8fWciVPPi6X85Y6QGpxR95SBzi+lrCwoHLvc1pPPDU1laioKCIjI9Hr9fTv35+kpKQS2xQFOMClS5dQqarBUKpGg6lLV3LffIfTqX9ydsVaLj36BIpGi9+SxYTcNZhaLRsROPoZdOuSwGRydYurxOVLsk6c6MPff7u6RUII4f6cFuLZ2dnUqVPH/rPBYCA7O7vUdp9//jk9e/bkrbfe4pVXXnFWc9yTRoOpcxdyX3+bnN/3c3bl91x6bASKTo/fZ58QcvedtkB//v/QJf/s9YEeFaXw4ou2JVnbtYOXXvLh5581XLzo6pYJIYR7ctpw+g8//MAvv/zC9OnTAVixYgWpqalMmjSpzO1Xr17Nr7/+yhtvvFHhfs1mC1qtly/VabHApk2wbBl8/TVkZtpuDw2FwYNh2DCIjwe93qXNdAazGZ5+Gr78Es6ft93m4wPdukHfvtCnDzRpYuu5CyFEdee0EN+1axfvvvuu/TvuDz/8EIAnn3yyzO2tVivt27fnt99+q3C/Hv+d+LWyWtFu24rP6uX4rF6JJssW6NaQEIx9+lMwcDDGrj1Ar3f/Wq5BSEgQ339/kaQkDUlJWvbuLf7g1qCBlbg422VNu3SxcNm3Mm7JW46Lt9QBUos78pY6wEu+E4+JiSEtLY309HSMRiNr1qwhLi6uxDZpaWn2f69fv56oqChnNcdzqdWYYzuRN/1Ncnbv48zqn7g4YiSKnz++X35O8H3DqNWiEUHPPAVr1oDR6OoWO4ROB506WXjlFSPr1l0kNTWXuXMvMXCgibNnVSxerOehh/xp2jSQIUP8eP99Hfv3q+XMdiFEteK0njjAhg0bmDFjBhaLhSFDhjBy5Ejmzp1Ly5YtiY+PZ9q0aWzevBmtVkuNGjWYNGkS0dHRFe6z2vXEy2O1ot2xvbiHnnHCdnONYIx9+tl66N3ibGPRHqii42I2w44dGtats/XSU1OLe+n16hX10i107WomqPwPsFXGY19jV/CWOkBqcUfeUgdUbU/cqSHuDBLiZbBa0f62ndD/rsXy1TI0J47bbq4RjDGhLwUD78TY3bMC/VqOS3a2ivXrNSQna1m/XsuZM7YvzLVahY4dLcTFWYiLM9O8udUl36V7xWsM76kDpBZ35C11gIR4hSTEyxcWFsSp7HNod+7AZ9UKfL5bieZ4OgDWoBolA93X18Wtrdj1HheLBXbtUpOUpCU5Wcvu3WoUxZbcdeuW7KUHBzu61WXzlteYt9QBUos78pY6QEK8QhLi5StVi6IUB/rqFcWBHhhUHOg94t0y0B11XP7+29ZLT0rSsn69htOnbaeBaDQK7dvbeunx8WZatnReL91bXmPeUgdILe7IW+oACfEKSYiXr8JaFAXtrt+KAz39GFAY6L372AI9rqfbBLozjovFAqmptl56UpKWnTuLe+nh4Vb7sHv37mZCQhz3vN7yGvOWOkBqcUfeUgdIiFdIQrx8la5FUdDu3lkc6MeOAmANCMSY0IeCxMJA9/NzcovLVxXHJScHNmzQFg69a/j7b1svXa1WuO0229B7fLyZVq2sqG9gHoe3vMa8pQ6QWtyRt9QBEuIVkhAv33XVoihof99lC/RVK9AcSwMKA713gi3Q43tVeaBX9XGxWmHPnqJeuoYdOzRYrbZeeu3aVrp3tw27d+9uoVata/sv4y2vMW+pA6QWd+QtdYCEeIUkxMt3w7UoCtrU3YWBvhzN0TTbzf4BFFwe6P7+jmlwBVx9XM6ehZSU4l56dratK65SKdx6q5UePWy99DZtrGiusoCgq2txFG+pA6QWd+QtdYCEeIUkxMvn0FoUBe3/fi8O9LS/bDf7B1DQK8E2Dz2+t9MC3Z2Oi6LA3r1qkpNtvfRt2zRYLLZees2atl56XJyZHj0shIWV/u/kTrXcCG+pA6QWd+QtdYCEeIUkxMvntFoUBe2eVHxWrUC/ajnav47Ybvb3p6DnZYEeEOCwp3Tn43L+vK2XnpxsO+s9M7P4C/M2bSz2JWFvu83WS3fnWq6Ft9QBUos78pY6QEK8QhLi5auSWhQFzZ7/4bPa1kPXHjlsu9nPD2NhoBf0TLjhQPeU46IosH+/mqQk22IzW7dqMJlsvfSQEIVu3cwMHqyjXbtcDAaP+q9Wiqcck8qQWtyPt9QBEuIVkhAvX5XXoiho9u6xLf26agXaw4dsN/v5YYzvXRzo13GFEk89Lrm58MsvWnuoHz9e3Etv2dJ2clx8vIV27SxotS5s6HXw1GNSFqnF/XhLHSAhXiEJ8fK5tBZFQfPH3uJAP3TQdrOvb3Gg9+pT6UD3huOiKHDwoJqtWwNYudLMli0ajEZbL71GDYWuXW2BHhdnpm5d9/9v6A3HpIjU4n68pQ6QEK+QhHj53KYWRUGz7w98Vi3HZ/UKtAcP2G729cUY18v2HXrvPiiB5b8w3aYWByiqJTcXNm3S2BebOXasuJferFlxL719e4tbXireG4+JN/CWWrylDpAQr5CEePncshZFQbN/X3GgH/jTdrOPD8YePW2BntAXJahGiYe5ZS3XqaxaFAWOHFHZA33TJg0FBbZeemCgwh132AI9Pt5MvXru8V/U24+Jp/KWWrylDpAQr5CEePk8oZYSgf7nfqAo0OMpSByMsU8/lKAaHlFLZVWmlosXYfPm4l76X38V99KbNCle471jR4vLLkZX3Y6Jp/CWWrylDpAQr5CEePk8rRbNn/uLA33/PgAUvR5jj3h87hxETsvbsEQ3xiXXD3Wg6zkuR46oWLfOFugbN2q4dMn2O/D3V7jjDot9SdgGDaruv6+nvb4qIrW4H2+pAyTEKyQhXj5PrkVz4M/iQN/3h/12a+3amDp2xtSpM6ZOt2Nu3pKrLpHmZm70uOTn23rpRYvNHDpUXH+jRhb7yXGdOlmcev0aT359XUlqcT/eUgdIiFdIQrx83lKL5vBBav6+nfyfk9Ft3ogm44T9PmtQDUwdYzHFdsYUezvmNm1xy7PALuPo43L0qIrkZNv10n/5RcPFi7Zeup+fwu2324bde/Qw07ChY/9re8vrC6QWd+QtdYCEeIUkxMvnlbUoCur0Y+g2b0S3ZRO6zRvtC8yAbU666bb2haHeGdNt7R26cpwjOPO4FBTA1q0a+xrvf/5Z3Eu/+WZr4Rnvtl76ja6Q65WvLy/gLbV4Sx0gIV4hCfHyVZdaVNnZ6LZuQr95I7rNm9Ds24uq8GWsaLWYW7fF1Ol22xB8h1iU4JAqbHlpVXlcjh9X2YfdU1K05OXZeum+vgqdOtl66XFxZm65RbnmUw2qy+vL03hLLd5SB0iIV0hCvHzVtRbVmRx027baeutbN6HdvQuVxQKAolJhad4SY+F36qaOnVHCw53Z9FJcdVyMRti+XUNSkq2nvm9fcS+9QYPiXvrtt1sqNXhRXV9f7s5bavGWOkBCvEIS4uWTWgrl5qL7bXvxEPxv21EVFNjvNjeKtgV64RC8NbKBg1pdNnc5LpmZxb30DRu0XLhg64rr9QqxsUW9dAuNG1vL7KW7Sx2OILW4H2+pAyTEKyQhXj6ppRwFBWh370K3ZSP6zRvRbtuKOrd435b6kbZA73Q7pk63Y7mlkUOntbnjcTGZ4Lffinvpe/YU99Lr17cWXonNQteuZvtKue5Yx/WSWtyPt9QBEuIVkhAvn9RSSWYz2r3/K+ypb0a3ZSPqnBz73dbaYYWh3hlj7O1Ymre4oWltnnBcsrNVrFtnC/T167WcO2f7EKPTKXTsaJvCduedvoSFXXD3yQCV4gnHpLK8pRZvqQMkxCskIV4+qeU6Wa1oDh4oDPXCk+UyM4rvrhFcOK3tdkyxnTC3vrZpbZ52XMxm2LlTXTj0ruX334s/wOh0CtHRVpo3t9KsmZUWLSw0b27FYLj2E+VcydOOSUW8pRZvqQMkxCskIV4+qcVBFAX1saMlp7X9daT4bj8/TO06FA/B39qOiuZvefpxOXXK1kvfvduPXbss7Nunts9NL1Kzpi3YbX9swd64sfWGp7U5i6cfk8t5Sy3eUgdIiFdIQrx8UovzqLMy7YGu27IZ7b699vsUna70tLYawfb73a2W61VUh9UKaWkq/vhDwx9/qAv/aEhLU5fYXq1WaNiwdLhHRrq+1+4txwS8pxZvqQMkxCskIV4+qaXqqHJOF09r27IRbervJaa1mVu2sgV6x84ED+jNKZWfi1t84652THJzYf9+Nfv2lQz3ou/XiwQGKjRvbqFZs5IBH1T++5TDufvr61p4Sy3eUgdIiFdIQrx8UosL5eai27HN/p26bueOktPaohvbvlMvnK9urVffhY29PtdzTBQFMjJU9kAvCvdDh9RYLCXDvUGD4t56UbDffLPilKXyPe71VQFvqcVb6gAJ8QpJiJdPanEj+fnodu9Et3kjATu3Yf11I+q8XPvdlgZRmDp2sg/BWxo6dlqbMzjymOTnw8GDavbutYX7vn22cD91quSQvK+vQtOmJcO9WTMrtWrd2NuWx7++LuMttXhLHVC1Ia512LMIIYr5+toXkwkIC+J05hm0e1JtvfTCleV8l32J77IvAbCGhWPsZDv73VQ0rU2tvsqTeC5fX4iJsRITYwXM9ttPnlTZA/3ynvvu3SW74wZD6e/ao6OtXjH9TYhrIT1x+fTnlry+FqsVzZ/7bSfLbdmIbtNGNNlZxXcHhxRPa+vUGXOrNqDTVW3Dr+CqY2IywZEj6hLfs//xh5oTJ0p+yNFqi6e/NW9e8fQ3r399eSBvqQNkOL1CEuLlk1rcU6VqURTUaX+h21J4YZctm9Ck/VV8t78/pts62L9TN93aDvyq9mQ5dzsmZ89S6iS6q01/s51MZ6FLlwDy8tynlhvhbsflenlLHSDD6UJUPyoV1psbUnBzQwrufQAAdWbGZdPaNqH/ZT36X9YDhdPa2t5WuAZ8J9u0tqAaLmu+K4SEQKdOFjp1sthvs1pt11u/cvrbxo0afv21+O1OpYKGDQNKnUgXGal487cYwgs5tSeekpLC9OnTsVqtDBs2jBEjRpS4f9GiRSxbtgyNRkPNmjWZMWMG9erVq3Cf0hMvn9TinhxViyrnNLqtW0pOa7NaAVDU6uJpbbG3Y+rYCaV27Rt+zst58jHJzYU//yweij94UM/vvytlTn8r6q0X994t1HDjz0eefFwu5y11gJcMp1ssFhISEli0aBEGg4GhQ4cye/ZsGjVqZN9my5YttG7dGj8/P5YuXcq2bduYM2dOhfuVEC+f1OKenFWLKvcC2m1b0W3dVDytzWi0329u3KTktLaIij8gX423HZOTJy+QmVl6+tvBg6Wnv0VGljyJrnlzKzffbEXrBmOZ3nJcvKUO8JLh9NTUVKKiooiMjASgf//+JCUllQjx2NhY+7/btGnDqlWrnNUcIbyOEhiEKa4npriethvy89Ht+s3WU9+8Ed32bWg//Ri/Tz8GwNLgpsKeuu3iLpabb3H7aW3OpFJBRIRCRISFnj2Lh+QLCuDAgdJnyP/4o5Yffyx+y/T1VWjSpHS43+j0NyGuhdNCPDs7mzp16th/NhgMpKamlrv9119/TdeuXZ3VHCG8n6+v/XKqAJhMxdPatti+V/f9z1J8/7MUAEu4ocR11S3Nmnv1tLbK8vGp3PS3ffvU7N+vLrxATPHMAZn+JqqSGwwGwcqVK9mzZw+fffbZVbcNDfVHq3XsEk4VDVV4GqnFPbmsloju0Lu77d9WK+zdCykp8MsvaDZsQLPyW3xXfmu7PzQUunSBrl1tf9q2LTWtrTofk7AwaNGi5G1mMxw8CKmpl/9Rs26dmnXrirfTaqFpU2jVquSfiAjHDIZ4y3Hxljqg6mpxWogbDAaysornvWZnZ2MwGEptt2nTJubPn89nn32GvhIfVc+cuejQdsr3MO5JanGSOjfBXTfBXQ/ZprX9dQR90RnwmzehWb0aVq8GQPEPwNS++GptIb27cyrXXOHuPYUjj0nt2hAXZ/tT5Nw52/Q324p0xT33PXtULF1avF1oqFLqDPkmTa7t6m9u9fq6Ad5SB3jJd+IxMTGkpaWRnp6OwWBgzZo1vP322yW2+eOPP5g0aRIfffQRtWrVclZThBBlUamwNryF/Ia3kH/fgwCoM04UTmuzDcHrN6xDv6G4S1krLBxLRD2sdSOwRkTY/l2nLtaIeraf60RUeFnW6iI4GGJjLcTGlj/9zTY0r2HTJg0bN14+/U2hYUOFZs1KhnuDBjL9TZTm1ClmGzZsYMaMGVgsFoYMGcLIkSOZO3cuLVu2JD4+nocffpgDBw4QFhYGQN26dZk/f36F+5Sz08sntbgnT65Fdfo0uq2b0W3eiP/+PZiPpaPJzECVn1/uY6yhoVjrRGCJiLCFe13b35a6EfbwV4JquPSkOnc6Jnl5Jae/FfXcz54t+fsJCCg9/a15cwu33OI+tdwIdzomN8orppg5i4R4+aQW9+QttdjrUBRUZ3JQZ2SgyTyBOjMTdcYJ1JkZaAr/Vmdmor5wvtx9WQMCsUZEYK1bD2vdurbAr1vYm69bD2tEPZSaNZ0W9O5+TBSFSk9/Mxigfn0LUVFWoqKsNGigFP5tJSJCcYtpcJXh7sfkWnjFcLoQwkupVCg1a2GpWQtLy5jyN7twvoyAz0SdeQJNRgbqzBNoDx4o9/GKjw/WOnUvG74vDPzCsLdG1MMaFo5TrlXqYhVNfzt4sOT0t/R0Lb//rua330r/HrRahXr1FHvAR0UpNGhQHPY1a5ZeV154FglxIYRTKEE1sATVwNK4SfkbXbqEOisTTWaGLewv791n2n7WbdmEqpwBQ0WjsX0nX/i9fIkefR3b0L21Tl28ZX6Xjw+0bGmlZcvi6W9hYUFkZuaSmani6FE1x46pOHZMTVqammPH1Bw9qiIlpey3+sDAkqF+0022HnyDBrbbq3h5fnEdJMSFEK7j54f15oZYb25Y/jYmE+rsrMJh+sIefcZl/87KRPv7LlS/bS93F1b7CXl1sdaNgOiG+NSo5TUn5Gm1EBmpEBlpKfP+vDxIT7cFvC3obeF+9Kgt7P/4o+zRjPDwkr33y3vzdesq3jgI4nEkxIUQ7k2nw1o/Emv9yPK3sVpRnTpl68UXBXxR777wb+2f+1D9vsv+kCuXQ7eGhGCtW6/4hLyi3n3RUL4bnJB3vQICoGlTK02bApQMekWB06dVHD1q68FfHvBHj6rZuVPN9u2l01qnU6hfv/j796go5bLv5a2EhHjkr8rjSIgLITyfWo1iMGA2GKDNrWVvoyiozp5BnZFBzYtnuLDvUMnefWYG6uPpaPftLfdprAGBhb35wh68/eS8CPtJeUqtWh6VXioV1K6tULu2wm23WUvdbzbDiROqwnAv3Ztfv77sGAkKKhnwDRpYC4frFSIjrfj6Oruy6kFCXAhRPahUKKE1sYTWhLAg8tuXffawKvdC6RPyMjJQZ2XYv7PXHjpY7tOUPCGv7hVn3RdOsws3eMwJeVothb1sC3fcUXq4PjfXNlRf1JO/POCPHFGzZ0/ZddapU/Js+pYtoWZNDQ0aWKlTR+bEV5aEuBBCXEYJDMISHYQlunH5G+Xn2wI+K9N+Qt7lZ92rMzOvfkKeoU7xHPqICKx1IkqGvYeckBcYCM2aWWnWDMoaqj91SlWq914U9tu3a9i69fJRC9t5CXq9QmTk5SfdlRyuDw6usvLcnoS4EEJcK1/fyp2QdzK7uEefmXFF2GegTd1d8Ql5tcNsPfrCHnyZK+S58XrjKhWEhyuEhyu0a1d6qN5kguPHbaF+5ow/e/YUlBi2P3y47IgKDi49VF8U8PXrK/j4OLsy9yEhLoQQzqDTYa1XH2u9+uVvY7Wi+vvv4hPyMk4U9+6LTsg7+Ceq1N3l78PPj5rBISghIVhDQlFCQlCCQ7AW/R0ailJ0f3AISkiofbsrL3BT1XQ6uPlmhZtvthAWBqdOGUvcn5uL/QS7K3vzBw6oSU0tPVSvUinUravYh+qvnEIXHu5dQ/US4kII4SpqNUp4OObwcGjdtuxtik7Iy8wsEfZFvXv9hXNw6m/bfPs/95c7hF/mrv0DSoV90c+XfygocVtw4QeAKlgKLjAQWrSw0qJF6V68otguD1vWd/HHjqnZskXD5s2lTzD08VHsc+HL6s3XuHLagpuTEBdCCHd22Ql5luYtSt0dFhZETtESn1YrqgvnUZ09i/rsGVRnz6I6dxb12bPFt132s+3fZ1CfOF7hWfllsQYGlez1h4ReEfYhKKGhhb3/EPvfSnCIQ07qU6nAYFAwGBQ6dCgd8kajbai+rO/ijx1Tc/Bg2TMIQkMvD/eSvfn69RW3O01BQlwIIbyFWm0L0eAQrFE3XdtjLRZU58+V+ACgPndZ2J+57APAueIPBeqjaWj3Xts64dYawSWDPSQU6oQR4BNQ9khA0XY1gqnsWLheDw0bKjRsaOHKE+4Azp+nnIBXsW+fmt27S3/QUKsVIiKUUr33op/Dw6t+GVsJcSGEEKDRoITWRAmtSel+7VWYzajOnUN97gyqMyV7++pzZ0veZr/vDNrDh1BdzLPv5mpr5ikqFUpwcGHvP7TEKMDlYV/WbVcu1FOjBsTEWImJKV2t1WobqrctXVu6N795s4ZNm0qntZ+fLdh794aJE6/1l3h9JMSFEELcGK0WpVYtLLVqXftjjUZU585RW2PizOH0kr3/wrAv0fsv/Ft7YD+qS5cq/TSKWl1qWL/4a4ArT/4LoV5IKBH1Q+jUMgQlILDEB4CCguKh+rJ68//9L7z8cqUHDW6IhLgQQgjX0etRwsIgLAhzzYhre2xBQYlgV5/NqdTXAJqME6gKCir9NIpWixIcXOLs/9ohIbQuOiEwPBRr4+KvAYJjb+NvddVcPUZCXAghhGfy8UExGLAYDNf+2EuXisPefh7AmQo/AKjPnkV17Cgqk6nifYeEwL6/qmRVPglxIYQQ1Y+fH1Y/P6hT99oepyhw8WJx77/Ud/5nCGjRtMqW1ZUQF0IIISpLpYKAAKwBARBRr4zz3iEgLAhOXdsZ+9fLi9atEUIIIaoXCXEhhBDCQ0mICyGEEB5KQlwIIYTwUBLiQgghhIeSEBdCCCE8lIS4EEII4aEkxIUQQggPJSEuhBBCeCiVoiiKqxshhBBCiGsnPXEhhBDCQ0mICyGEEB5KQlwIIYTwUBLiQgghhIeSEBdCCCE8lIS4EEII4aGqTYinpKSQkJBAr169WLBgQan7jUYjzz33HL169WLYsGEcP37cBa2snKvV8u233xIbG8ugQYMYNGgQy5Ytc0Err+6ll16iU6dODBgwoMz7FUVh2rRp9OrVi8TERPbu3VvFLay8q9WydetWbrvtNvsxeffdd6u4hZWTmZnJgw8+SL9+/ejfvz+ffPJJqW085bhUphZPOS4FBQUMHTqUgQMH0r9/f+bNm1dqG094D6tMHZ7y/lXEYrEwePBgnnzyyVL3VckxUaoBs9msxMfHK8eOHVMKCgqUxMRE5eDBgyW2+eyzz5SJEycqiqIo3333nTJq1CgXtPTqKlPLN998o0yePNlFLay8bdu2KXv27FH69+9f5v3r169XHnvsMcVqtSq7du1Shg4dWsUtrLyr1bJlyxZlxIgRVdyqa5edna3s2bNHURRFuXDhgtK7d+9Sry9POS6VqcVTjovValVyc3MVRVEUo9GoDB06VNm1a1eJbTzhPawydXjK+1eRjz/+WBk9enSZr6OqOCbVoieemppKVFQUkZGR6PV6+vfvT1JSUoltkpOTufPOOwFISEhg8+bNKG64Dk5lavEU7du3Jzg4uNz7k5KSGDx4MCqVijZt2nD+/HlOnjxZhS2svKvV4inCw8Np0aIFAIGBgTRs2JDs7OwS23jKcalMLZ5CpVIREBAAgNlsxmw2o1KpSmzjCe9hlanDk2RlZbF+/XqGDh1a5v1VcUyqRYhnZ2dTp04d+88Gg6HUf+bs7Gzq1q0LgFarJSgoiDNnzlRpOyujMrUA/PTTTyQmJvLss8+SmZlZlU10mCtrrVOnjse+CQPs3r2bgQMH8vjjj3Pw4EFXN+eqjh8/zr59+2jdunWJ2z3xuJRXC3jOcbFYLAwaNIjOnTvTuXPnMo+LJ7yHXa0O8Jz3rxkzZvDCCy+gVpcdpVVxTKpFiFc3PXr0IDk5mdWrV9O5c2fGjRvn6iZVey1atCA5OZlVq1bx4IMP8vTTT7u6SRXKy8vj2WefZcKECQQGBrq6OTekolo86bhoNBpWrlzJhg0bSE1N5cCBA65u0nW5Wh2e8v61bt06atasScuWLV3ajmoR4gaDgaysLPvP2dnZGAyGUtsUfeIzm81cuHCB0NDQKm1nZVSmltDQUPR6PQDDhg1z2xOPrubKWrOyskrV6ikCAwPtw4jdunXDbDaTk5Pj4laVzWQy8eyzz5KYmEjv3r1L3e9Jx+VqtXjScSlSo0YNOnbsyC+//FLidk95DytSXh2e8v61c+dOkpOTiYuLY/To0WzZsoWxY8eW2KYqjkm1CPGYmBjS0tJIT0/HaDSyZs0a4uLiSmwTFxfH8uXLAfjxxx+JjY11y+9qKlPL5d9PJicnc8stt1R1Mx0iLi6OFStWoCgKu3fvJigoiPDwcFc367qcOnXK/l1YamoqVqvVLd9gFUXh5ZdfpmHDhjzyyCNlbuMpx6UytXjKccnJyeH8+fMA5Ofns2nTJho2bFhiG094D6tMHZ7y/jVmzBhSUlJITk5m9uzZxMbGMmvWrBLbVMUx0Tp0b25Kq9UyadIkHn/8cSwWC0OGDCE6Opq5c+fSsmVL4uPjGTp0KC+88AK9evUiODiYd955x9XNLlNlalmyZAnJycloNBqCg4OZOXOmq5tdptGjR7Nt2zbOnDlD165deeaZZzCbzQDce++9dOvWjQ0bNtCrVy/8/PyYMWOGi1tcvqvV8uOPP/LFF1+g0Wjw9fVl9uzZbvcGC/Dbb7+xcuVKGjduzKBBgwBbbRkZGYBnHZfK1OIpx+XkyZOMHz8ei8WCoij06dOHHj16eNx7WGXq8JT3r/JU9TGRS5EKIYQQHqpaDKcLIYQQ3khCXAghhPBQEuJCCCGEh5IQF0IIITyUhLgQQgjhoarFFDMhhG3Oql6vx8fHx37be++9R/369R32HMePH2fIkCFs3brVYfsUQpRPQlyIamTevHk0btzY1c0QQjiIDKcLUc01adKEefPmMWjQIBISEvjxxx/t96WkpDB48GASExMZPnw4R48etd/39ddfM3DgQAYOHMiQIUP4+++/7fe98847DB48mISEBHbs2FGl9QhRnUhPXIhq5Nlnn7UPp2s0Gr799lsA1Go1K1eu5MiRI9x77720a9cOgBdffJHPPvuMRo0asWzZMsaOHcuyZcvYunUrH374IUuXLiUsLIy8vDy0Wi35+fmcPXuWNm3a8Pzzz7Nq1SpmzZrFl19+6bKahfBmEuJCVCPlDacPGzYMgIYNG9K8eXN2796NSqWiadOmNGrUCIAhQ4YwefJkcnNzWb9+PYMGDSIsLAzAfhERAH9/f3r06AFAmzZteOONN5xdlhDVlgynCyEcqugKVGDr4RetIS+EcDwJcSEE33zzDQBpaWn88ccftGnThjZt2rB//34OHz4MwPLly2nevDmBgYF0796dlStX2r8Hz8vLo6CgwGXtF6K6kuF0IaqRy78TB5g2bRoAFouFwYMHc+nSJaZMmUKtWrUAePPNNxk7dixms5maNWvy1ltvAdCxY0dGjBjBI488gkqlQq/XM3/+/KovSIhqTq5iJkQ116RJE3bu3Fnie20hhGeQ4XQhhBDCQ0lPXAghhPBQ0hMXQgghPJSEuBBCCOGhJMSFEEIIDyUhLoQQQngoCXEhhBDCQ0mICyGEEB7q/wGol9pN/atx5QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_net(model, criterion, optimizer, dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of LeNet5(\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coupekv/.local/lib/python3.10/site-packages/torch/ao/quantization/observer.py:177: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('quant.scale', tensor([0.0079])),\n",
       "             ('quant.zero_point', tensor([0])),\n",
       "             ('feature_extractor.0.weight',\n",
       "              tensor([[[[ 0.0033,  0.1512,  0.0427,  0.0855, -0.0427],\n",
       "                        [ 0.0132,  0.3123,  0.2696,  0.0756,  0.1184],\n",
       "                        [ 0.1743,  0.3880,  0.3814,  0.4175,  0.2926],\n",
       "                        [-0.0362,  0.3978,  0.2367,  0.1545,  0.0822],\n",
       "                        [ 0.1841,  0.2367,  0.2992,  0.2564,  0.2071]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0386,  0.1416,  0.0676, -0.1512,  0.0064],\n",
       "                        [ 0.2349,  0.1834,  0.1738,  0.2542,  0.1384],\n",
       "                        [ 0.1834,  0.2317,  0.3733,  0.3282,  0.0740],\n",
       "                        [-0.0097,  0.0354,  0.2703,  0.4087,  0.1673],\n",
       "                        [ 0.1770, -0.0290,  0.2092, -0.0386,  0.1995]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0296, -0.1867,  0.1778, -0.0415, -0.0593],\n",
       "                        [ 0.1541, -0.0178, -0.0563,  0.0119,  0.0030],\n",
       "                        [ 0.1600,  0.2607,  0.1837,  0.2193, -0.0681],\n",
       "                        [ 0.3259,  0.1067,  0.3407,  0.2548,  0.1896],\n",
       "                        [ 0.3763,  0.2874,  0.1244,  0.0652,  0.1067]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0948,  0.0711,  0.2162,  0.2133, -0.0089],\n",
       "                        [-0.0592,  0.1007, -0.0118,  0.1244,  0.3495],\n",
       "                        [ 0.0089,  0.1955,  0.2281,  0.3199,  0.1748],\n",
       "                        [-0.0829,  0.2607,  0.3762,  0.0681,  0.3288],\n",
       "                        [-0.1244,  0.2340,  0.0059,  0.3021,  0.2399]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2131,  0.0470,  0.2381,  0.0313, -0.0783],\n",
       "                        [ 0.2663,  0.3603,  0.3008,  0.2507,  0.1034],\n",
       "                        [ 0.1253,  0.3979,  0.0783,  0.2225,  0.3227],\n",
       "                        [ 0.1347,  0.1253,  0.2977,  0.0971, -0.0157],\n",
       "                        [-0.1159,  0.1191,  0.1943, -0.1159,  0.1598]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0077,  0.1934,  0.0825,  0.0877,  0.2217],\n",
       "                        [ 0.2913,  0.1856,  0.2630,  0.1495,  0.2888],\n",
       "                        [ 0.2346,  0.1960,  0.3274,  0.0670,  0.0309],\n",
       "                        [ 0.2088,  0.1599,  0.2707,  0.1985,  0.0309],\n",
       "                        [ 0.1882,  0.0180,  0.2140,  0.1908, -0.1109]]]], size=(6, 1, 5, 5),\n",
       "                     dtype=torch.qint8, quantization_scheme=torch.per_channel_affine,\n",
       "                     scale=tensor([0.0033, 0.0032, 0.0030, 0.0030, 0.0031, 0.0026], dtype=torch.float64),\n",
       "                     zero_point=tensor([0, 0, 0, 0, 0, 0]), axis=0)),\n",
       "             ('feature_extractor.0.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-1.3539e-04,  1.9401e-01,  5.2945e-03,  1.2155e-03,  5.8358e-02,\n",
       "                      -2.4510e-04], requires_grad=True)),\n",
       "             ('feature_extractor.0.scale', tensor(0.0396)),\n",
       "             ('feature_extractor.0.zero_point', tensor(5)),\n",
       "             ('feature_extractor.3.weight',\n",
       "              tensor([[[[-0.0641, -0.0055,  0.0421,  0.0458,  0.0805],\n",
       "                        [-0.0256,  0.1446,  0.1153,  0.1775,  0.0952],\n",
       "                        [ 0.1043,  0.0695,  0.0201,  0.0567,  0.1501],\n",
       "                        [-0.0604, -0.0878, -0.0677,  0.0165,  0.0165],\n",
       "                        [-0.0732, -0.0933, -0.1610, -0.2343, -0.1190]],\n",
       "              \n",
       "                       [[ 0.0348,  0.0146,  0.0092,  0.0878, -0.0037],\n",
       "                        [ 0.0092,  0.0183,  0.1098,  0.1867,  0.0641],\n",
       "                        [ 0.0915,  0.0311,  0.0842,  0.0311,  0.1482],\n",
       "                        [-0.0531, -0.0512, -0.0092, -0.0750, -0.0092],\n",
       "                        [-0.0659, -0.1354, -0.1739, -0.2160, -0.1336]],\n",
       "              \n",
       "                       [[-0.0586,  0.0000, -0.0458,  0.0787,  0.2013],\n",
       "                        [ 0.0677,  0.1080,  0.1080,  0.2196,  0.1812],\n",
       "                        [ 0.0073,  0.0732,  0.0659, -0.0421,  0.0567],\n",
       "                        [ 0.0092, -0.0439, -0.1190, -0.1665, -0.1501],\n",
       "                        [ 0.0476, -0.0128, -0.2251, -0.1922, -0.1263]],\n",
       "              \n",
       "                       [[ 0.0476,  0.0586,  0.0329,  0.0952,  0.1098],\n",
       "                        [-0.0238,  0.1482,  0.1299,  0.1116,  0.1830],\n",
       "                        [ 0.0586,  0.0311,  0.1409,  0.1592,  0.0769],\n",
       "                        [-0.0586, -0.0641, -0.0018, -0.0092,  0.1098],\n",
       "                        [-0.0659, -0.1336, -0.2269, -0.0421, -0.0348]],\n",
       "              \n",
       "                       [[ 0.0128, -0.0897,  0.0824, -0.0311,  0.0055],\n",
       "                        [ 0.0476, -0.0073,  0.0018,  0.1427,  0.1958],\n",
       "                        [ 0.0732,  0.0110,  0.1226,  0.0933,  0.1775],\n",
       "                        [ 0.0769,  0.0055, -0.0128,  0.0348,  0.0641],\n",
       "                        [ 0.0073, -0.0458, -0.1318, -0.1720, -0.0165]],\n",
       "              \n",
       "                       [[-0.1299, -0.1318,  0.0000,  0.0750,  0.0146],\n",
       "                        [-0.0750,  0.1007,  0.0622,  0.1958,  0.1830],\n",
       "                        [ 0.0128,  0.1537,  0.1647,  0.0622,  0.0384],\n",
       "                        [ 0.0952,  0.0769,  0.0622, -0.0604,  0.0018],\n",
       "                        [ 0.0055, -0.1080, -0.1025, -0.1830, -0.1373]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0208,  0.0763,  0.0451,  0.1272, -0.0104],\n",
       "                        [ 0.0116,  0.1376,  0.0694,  0.0740,  0.1053],\n",
       "                        [ 0.1053,  0.0012,  0.0706,  0.0208,  0.1018],\n",
       "                        [-0.0521, -0.0231, -0.0648,  0.0046,  0.0972],\n",
       "                        [-0.0035, -0.1087, -0.0868,  0.0428,  0.0717]],\n",
       "              \n",
       "                       [[ 0.0532,  0.0868,  0.0636, -0.0416, -0.0416],\n",
       "                        [ 0.0335,  0.0833, -0.0220, -0.0335, -0.0497],\n",
       "                        [ 0.0752,  0.0659,  0.0093,  0.0000, -0.0104],\n",
       "                        [ 0.0035, -0.1203, -0.0208, -0.0555, -0.0231],\n",
       "                        [-0.0567, -0.0532, -0.0891, -0.0844,  0.0035]],\n",
       "              \n",
       "                       [[-0.0509,  0.1249,  0.1296,  0.0879,  0.0393],\n",
       "                        [ 0.0393,  0.1006,  0.0868,  0.0254,  0.0093],\n",
       "                        [ 0.0139, -0.0625, -0.0231, -0.0521,  0.1261],\n",
       "                        [-0.1099, -0.0763, -0.1180, -0.0416,  0.0058],\n",
       "                        [-0.0960, -0.0868, -0.0509, -0.1168,  0.0231]],\n",
       "              \n",
       "                       [[ 0.0833,  0.0671,  0.1226,  0.0139,  0.0382],\n",
       "                        [ 0.0324,  0.0810, -0.0127,  0.0451, -0.0162],\n",
       "                        [ 0.0023,  0.0648,  0.0914,  0.1041, -0.0440],\n",
       "                        [-0.0717, -0.0139,  0.0127, -0.0324,  0.0972],\n",
       "                        [-0.0972, -0.0590, -0.0174,  0.0532,  0.0682]],\n",
       "              \n",
       "                       [[ 0.0509,  0.1087,  0.0347,  0.0821,  0.0729],\n",
       "                        [ 0.0405,  0.1215,  0.0567,  0.0844,  0.0879],\n",
       "                        [ 0.1018,  0.1180,  0.0590,  0.0960,  0.1168],\n",
       "                        [ 0.0474,  0.0486, -0.0960, -0.0266,  0.0682],\n",
       "                        [-0.1099, -0.0474, -0.1087, -0.0856, -0.0185]],\n",
       "              \n",
       "                       [[-0.0185,  0.1157,  0.1041,  0.0382,  0.0856],\n",
       "                        [ 0.0636,  0.0902,  0.1376,  0.1203,  0.0682],\n",
       "                        [ 0.1469,  0.0150,  0.0335,  0.0925, -0.0278],\n",
       "                        [ 0.0081,  0.0197,  0.0567,  0.0578,  0.1041],\n",
       "                        [-0.0972, -0.1203,  0.0324,  0.0451,  0.0150]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0850, -0.0127,  0.1092,  0.1231,  0.1066],\n",
       "                        [-0.0330,  0.0812,  0.0355,  0.0635, -0.0051],\n",
       "                        [ 0.0863,  0.0419,  0.0863, -0.0076, -0.0267],\n",
       "                        [ 0.0343,  0.0889,  0.0939,  0.0203, -0.1155],\n",
       "                        [ 0.0343,  0.0419, -0.0736, -0.0279, -0.0495]],\n",
       "              \n",
       "                       [[ 0.0749,  0.0597, -0.0279,  0.0013,  0.0584],\n",
       "                        [ 0.0508,  0.1041,  0.0724,  0.0647,  0.0127],\n",
       "                        [ 0.1130,  0.0381, -0.0051,  0.0241, -0.0584],\n",
       "                        [ 0.0495,  0.1219,  0.0762,  0.0635, -0.0838],\n",
       "                        [-0.0190, -0.0609,  0.0102,  0.0292, -0.0216]],\n",
       "              \n",
       "                       [[-0.0190, -0.0863,  0.1079,  0.0724,  0.0977],\n",
       "                        [-0.0787,  0.0089,  0.0482,  0.1485,  0.0089],\n",
       "                        [ 0.0076,  0.1269,  0.0724,  0.0762, -0.0368],\n",
       "                        [-0.0863,  0.1130, -0.0203, -0.0724, -0.0292],\n",
       "                        [-0.0457, -0.0051, -0.1092, -0.1168, -0.0089]],\n",
       "              \n",
       "                       [[ 0.0635,  0.0406,  0.0584,  0.1307,  0.0216],\n",
       "                        [ 0.0787,  0.0838,  0.1384,  0.1320,  0.0114],\n",
       "                        [ 0.0876,  0.1612,  0.1434, -0.0609, -0.0457],\n",
       "                        [ 0.0635,  0.0508, -0.0584, -0.0089,  0.0051],\n",
       "                        [ 0.0267, -0.0393, -0.0850,  0.0533,  0.0825]],\n",
       "              \n",
       "                       [[-0.0711, -0.0482,  0.0584,  0.0495,  0.0470],\n",
       "                        [-0.0228,  0.1092,  0.0673,  0.1320,  0.1117],\n",
       "                        [ 0.0622,  0.1333,  0.0241,  0.1422,  0.0419],\n",
       "                        [ 0.0749,  0.1320,  0.1015,  0.0914, -0.0724],\n",
       "                        [-0.0901,  0.0254,  0.0609, -0.0800, -0.0102]],\n",
       "              \n",
       "                       [[ 0.0444,  0.0736,  0.0457,  0.0724,  0.0927],\n",
       "                        [ 0.0127, -0.0178,  0.0825,  0.0178,  0.1028],\n",
       "                        [ 0.0254,  0.0241,  0.0457,  0.0749,  0.0102],\n",
       "                        [-0.0267,  0.0990, -0.0127,  0.0660, -0.0939],\n",
       "                        [-0.0140,  0.0216,  0.0533, -0.0013, -0.0279]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0618,  0.0223,  0.0092, -0.0276, -0.0604],\n",
       "                        [-0.0276, -0.0512, -0.1498, -0.0683, -0.0079],\n",
       "                        [-0.1551, -0.1393, -0.0460,  0.0604,  0.1406],\n",
       "                        [-0.0197,  0.0631,  0.0854,  0.0092,  0.1012],\n",
       "                        [ 0.1524,  0.0775,  0.1301,  0.1078, -0.0434]],\n",
       "              \n",
       "                       [[ 0.1130,  0.1524,  0.1327,  0.0526,  0.0775],\n",
       "                        [ 0.0670,  0.0171, -0.0867, -0.0079,  0.1261],\n",
       "                        [-0.0894, -0.0578,  0.0749,  0.0644,  0.0802],\n",
       "                        [ 0.0526,  0.1301,  0.0959,  0.1393,  0.0775],\n",
       "                        [ 0.0591,  0.0986,  0.0145,  0.1091,  0.1248]],\n",
       "              \n",
       "                       [[-0.0434, -0.0118,  0.0420,  0.0420,  0.0512],\n",
       "                        [-0.0907, -0.1445, -0.1682,  0.0158,  0.0263],\n",
       "                        [ 0.0289, -0.0854, -0.0053,  0.0447,  0.1248],\n",
       "                        [ 0.1078,  0.0723,  0.0381,  0.1353,  0.1472],\n",
       "                        [ 0.1038,  0.1156,  0.1170,  0.0420,  0.0736]],\n",
       "              \n",
       "                       [[ 0.0250,  0.0394,  0.0381, -0.0184, -0.0131],\n",
       "                        [-0.1432, -0.0105, -0.0710, -0.0066, -0.0145],\n",
       "                        [-0.1012, -0.0552, -0.0670,  0.1380,  0.1393],\n",
       "                        [ 0.0894,  0.0394,  0.0854,  0.0788,  0.1222],\n",
       "                        [ 0.1288,  0.0880,  0.0710,  0.0604,  0.0723]],\n",
       "              \n",
       "                       [[ 0.0670,  0.0171,  0.1051,  0.0210,  0.0039],\n",
       "                        [-0.0933, -0.1209, -0.0578, -0.0315, -0.0250],\n",
       "                        [-0.1275, -0.0565, -0.0276, -0.0315,  0.1222],\n",
       "                        [-0.0302, -0.0434, -0.0066, -0.0118,  0.0696],\n",
       "                        [ 0.1419,  0.1603,  0.1380,  0.0644,  0.0604]],\n",
       "              \n",
       "                       [[-0.0013, -0.0276, -0.0368, -0.0670,  0.0631],\n",
       "                        [-0.0788, -0.0539, -0.1340,  0.0026, -0.0302],\n",
       "                        [-0.1012, -0.1064, -0.0079,  0.0026,  0.0276],\n",
       "                        [-0.0565, -0.0053, -0.0039,  0.1104,  0.1051],\n",
       "                        [ 0.1301,  0.1669,  0.0145,  0.0894,  0.0434]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0300, -0.0469, -0.0612,  0.0560,  0.0703],\n",
       "                        [ 0.0300, -0.0065, -0.1328, -0.0521, -0.0417],\n",
       "                        [ 0.1237,  0.0000, -0.1094, -0.0912, -0.1459],\n",
       "                        [ 0.0977,  0.1120,  0.0378, -0.0234,  0.0794],\n",
       "                        [ 0.0677, -0.0391, -0.0847, -0.0026,  0.0573]],\n",
       "              \n",
       "                       [[-0.0143, -0.0365, -0.0313,  0.1654,  0.1302],\n",
       "                        [ 0.0573, -0.0404, -0.0300,  0.0781,  0.0495],\n",
       "                        [ 0.0469,  0.0925, -0.0794,  0.0260, -0.0143],\n",
       "                        [ 0.0221,  0.1198,  0.0768, -0.0365,  0.0625],\n",
       "                        [ 0.1263,  0.0951, -0.0078,  0.0847,  0.1276]],\n",
       "              \n",
       "                       [[-0.0716,  0.0247, -0.0026,  0.0417,  0.0078],\n",
       "                        [ 0.0586,  0.1172, -0.0508, -0.0508, -0.0443],\n",
       "                        [ 0.1133,  0.1029,  0.0104, -0.1381, -0.1263],\n",
       "                        [ 0.0026,  0.1355,  0.1172, -0.0599,  0.0755],\n",
       "                        [ 0.0156, -0.0130, -0.0508,  0.0247,  0.0247]],\n",
       "              \n",
       "                       [[ 0.0508,  0.0091, -0.0169,  0.0247,  0.0456],\n",
       "                        [ 0.0287, -0.1068, -0.1615, -0.1068, -0.1016],\n",
       "                        [ 0.0247, -0.0521, -0.1485, -0.1524, -0.0378],\n",
       "                        [ 0.0482, -0.0156, -0.0899,  0.0495,  0.0664],\n",
       "                        [ 0.0794,  0.0716,  0.0456,  0.0430,  0.0000]],\n",
       "              \n",
       "                       [[ 0.0013,  0.0130,  0.0274, -0.0039,  0.0000],\n",
       "                        [ 0.0247,  0.0547, -0.1094,  0.0195,  0.0260],\n",
       "                        [ 0.0873,  0.0573, -0.1146, -0.1042, -0.0156],\n",
       "                        [ 0.0287,  0.0768,  0.0573,  0.0443,  0.0391],\n",
       "                        [ 0.1094,  0.1328,  0.1029,  0.1172,  0.0026]],\n",
       "              \n",
       "                       [[-0.0469, -0.0300,  0.0391,  0.0625,  0.1094],\n",
       "                        [ 0.0729,  0.0495,  0.0169,  0.0234, -0.0990],\n",
       "                        [-0.0052,  0.0208, -0.0651, -0.1146, -0.1459],\n",
       "                        [ 0.0834,  0.0938,  0.0182, -0.0430, -0.1016],\n",
       "                        [ 0.0951,  0.0781,  0.0456,  0.0091,  0.1081]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0804,  0.1016, -0.0366,  0.0792, -0.1194],\n",
       "                        [ 0.0201,  0.1359,  0.1087, -0.0745, -0.0390],\n",
       "                        [ 0.1465,  0.0083,  0.0579, -0.0461, -0.1241],\n",
       "                        [-0.0225,  0.0284, -0.0213, -0.0355,  0.1087],\n",
       "                        [ 0.0449, -0.0827,  0.0059,  0.1324,  0.0733]],\n",
       "              \n",
       "                       [[ 0.0425, -0.0461, -0.0756,  0.0343, -0.1324],\n",
       "                        [ 0.1158, -0.0213, -0.0485,  0.0402, -0.0012],\n",
       "                        [ 0.0544,  0.0201, -0.0059, -0.0035, -0.0626],\n",
       "                        [ 0.0035, -0.0047, -0.0201,  0.0118,  0.0839],\n",
       "                        [-0.0544, -0.0213, -0.0579,  0.0284,  0.0272]],\n",
       "              \n",
       "                       [[ 0.0295,  0.1087,  0.0189,  0.0875,  0.0473],\n",
       "                        [ 0.0674,  0.0626,  0.1016,  0.0095,  0.0213],\n",
       "                        [ 0.0248,  0.0496,  0.0000,  0.0225, -0.0343],\n",
       "                        [-0.0815, -0.0449, -0.0402,  0.0709,  0.0461],\n",
       "                        [-0.1513,  0.0366, -0.0154,  0.1229,  0.0910]],\n",
       "              \n",
       "                       [[-0.0662,  0.0035, -0.0154, -0.1288,  0.0083],\n",
       "                        [ 0.0591,  0.0875,  0.0390, -0.1099, -0.0260],\n",
       "                        [ 0.0272, -0.0154,  0.0508,  0.0024,  0.0378],\n",
       "                        [ 0.0922, -0.0437,  0.1111,  0.0591,  0.0709],\n",
       "                        [ 0.0414,  0.0555,  0.0437,  0.0851,  0.0685]],\n",
       "              \n",
       "                       [[-0.1205, -0.0626,  0.0284,  0.0733,  0.0236],\n",
       "                        [-0.0366,  0.0591,  0.0804, -0.0697, -0.1158],\n",
       "                        [ 0.1052,  0.0473, -0.0437,  0.0804, -0.0957],\n",
       "                        [ 0.0579,  0.0496, -0.0496,  0.0555, -0.0071],\n",
       "                        [-0.0071,  0.0378,  0.0697,  0.0319,  0.0875]],\n",
       "              \n",
       "                       [[-0.0461, -0.0390,  0.0957,  0.0095, -0.0662],\n",
       "                        [ 0.0236,  0.0792, -0.0106,  0.0035, -0.0520],\n",
       "                        [ 0.1501,  0.0165,  0.1052,  0.0260, -0.0638],\n",
       "                        [-0.0343, -0.0130,  0.0804, -0.0295, -0.0035],\n",
       "                        [-0.0957,  0.0485,  0.0579,  0.0425,  0.0827]]]], size=(16, 6, 5, 5),\n",
       "                     dtype=torch.qint8, quantization_scheme=torch.per_channel_affine,\n",
       "                     scale=tensor([0.0018, 0.0012, 0.0013, 0.0019, 0.0013, 0.0021, 0.0019, 0.0016, 0.0015,\n",
       "                      0.0010, 0.0017, 0.0014, 0.0014, 0.0013, 0.0013, 0.0012],\n",
       "                     dtype=torch.float64),\n",
       "                     zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                     axis=0)),\n",
       "             ('feature_extractor.3.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0416, -0.0043,  0.0715,  0.0100, -0.0260,  0.0919,  0.0731, -0.1079,\n",
       "                      -0.0157, -0.0386, -0.0382,  0.0159, -0.1191,  0.0346,  0.0495, -0.0070],\n",
       "                     requires_grad=True)),\n",
       "             ('feature_extractor.3.scale', tensor(0.2775)),\n",
       "             ('feature_extractor.3.zero_point', tensor(52)),\n",
       "             ('feature_extractor.6.weight',\n",
       "              tensor([[[[ 0.0480,  0.0534,  0.0507,  0.0560,  0.0018],\n",
       "                        [ 0.0000,  0.0231,  0.0587,  0.0187,  0.0605],\n",
       "                        [-0.0276,  0.0498,  0.0142, -0.0614, -0.0009],\n",
       "                        [ 0.0285,  0.0338,  0.0071, -0.0560,  0.0249],\n",
       "                        [ 0.0098, -0.0374,  0.0311, -0.0036,  0.0587]],\n",
       "              \n",
       "                       [[-0.0240,  0.0641, -0.0027,  0.0036,  0.0258],\n",
       "                        [ 0.0169,  0.0196, -0.0222,  0.0302, -0.0178],\n",
       "                        [-0.0329,  0.0214,  0.0463,  0.0018, -0.0053],\n",
       "                        [ 0.0044, -0.0107,  0.0178, -0.0080,  0.0133],\n",
       "                        [ 0.0498,  0.0356, -0.0249,  0.0018,  0.0231]],\n",
       "              \n",
       "                       [[-0.0374,  0.0071, -0.0427,  0.0169, -0.0383],\n",
       "                        [ 0.0071,  0.0294,  0.0196, -0.0116,  0.0294],\n",
       "                        [-0.0623,  0.0231,  0.0409, -0.0080, -0.0142],\n",
       "                        [-0.0036, -0.0222,  0.0347,  0.0125, -0.0098],\n",
       "                        [-0.0374,  0.0027,  0.0276, -0.0356,  0.0365]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0071, -0.0107,  0.0000,  0.0658,  0.0383],\n",
       "                        [ 0.0329,  0.0365,  0.0347,  0.0125, -0.0151],\n",
       "                        [-0.0142, -0.0116, -0.0685, -0.0222,  0.0214],\n",
       "                        [ 0.0445,  0.0071,  0.0000, -0.0285,  0.0374],\n",
       "                        [ 0.0365,  0.0178,  0.1130,  0.1121,  0.0098]],\n",
       "              \n",
       "                       [[-0.0044,  0.0347, -0.0285,  0.0614, -0.0142],\n",
       "                        [ 0.0685,  0.0000,  0.0445,  0.0632,  0.0356],\n",
       "                        [ 0.0472, -0.0222,  0.0329,  0.0534,  0.0338],\n",
       "                        [ 0.0632, -0.0320,  0.0205, -0.0231,  0.0231],\n",
       "                        [ 0.0970,  0.0214, -0.0133,  0.0089, -0.0258]],\n",
       "              \n",
       "                       [[ 0.0071,  0.0187,  0.0036, -0.0160, -0.0062],\n",
       "                        [ 0.0507,  0.0214, -0.0454, -0.0338,  0.0142],\n",
       "                        [ 0.0329,  0.0205,  0.0240,  0.0489, -0.0400],\n",
       "                        [ 0.0027, -0.0107, -0.0151, -0.0489, -0.0240],\n",
       "                        [ 0.0418,  0.0205, -0.0169,  0.0044, -0.0347]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0984, -0.0049, -0.0285, -0.0020,  0.0394],\n",
       "                        [-0.0226, -0.0354, -0.0128,  0.0059, -0.0502],\n",
       "                        [ 0.0187,  0.0551,  0.0148,  0.0423,  0.1053],\n",
       "                        [ 0.0187,  0.0010,  0.0610,  0.0010, -0.0630],\n",
       "                        [-0.0394,  0.0354,  0.0079,  0.0187, -0.0374]],\n",
       "              \n",
       "                       [[-0.0344, -0.0384,  0.0089,  0.0571, -0.0030],\n",
       "                        [ 0.0059,  0.0177, -0.0216,  0.0000, -0.0403],\n",
       "                        [ 0.0679,  0.0138,  0.0531,  0.0453,  0.0394],\n",
       "                        [ 0.0492, -0.0118, -0.0216,  0.0020,  0.0403],\n",
       "                        [ 0.0118,  0.0315,  0.0157,  0.0157,  0.0098]],\n",
       "              \n",
       "                       [[-0.0659,  0.0315, -0.0226, -0.0276, -0.0089],\n",
       "                        [-0.0089,  0.0600, -0.0344, -0.0305,  0.0216],\n",
       "                        [ 0.0128,  0.0108, -0.0226,  0.0157, -0.0010],\n",
       "                        [-0.0207, -0.0157,  0.0236,  0.0049, -0.0403],\n",
       "                        [-0.0315,  0.0423,  0.0069,  0.0295,  0.0118]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0276,  0.0413,  0.0197, -0.0079, -0.0030],\n",
       "                        [ 0.0699,  0.0354,  0.0423,  0.0728,  0.0522],\n",
       "                        [-0.0276,  0.0059,  0.0472, -0.0187, -0.0708],\n",
       "                        [ 0.0472,  0.0531,  0.0079, -0.0738, -0.1014],\n",
       "                        [-0.0157,  0.0177, -0.0758,  0.0049, -0.0098]],\n",
       "              \n",
       "                       [[-0.0571, -0.0768,  0.0079, -0.0433,  0.0295],\n",
       "                        [-0.0364,  0.0069,  0.0118, -0.0197, -0.0364],\n",
       "                        [-0.0600,  0.0305,  0.0197, -0.0049,  0.0236],\n",
       "                        [-0.1210,  0.0246, -0.0216,  0.0512,  0.0039],\n",
       "                        [-0.1082, -0.0413,  0.0157,  0.0335,  0.0325]],\n",
       "              \n",
       "                       [[-0.0344,  0.0344,  0.0039, -0.0207,  0.0226],\n",
       "                        [-0.0305, -0.0305,  0.0413,  0.0108,  0.0522],\n",
       "                        [ 0.0443,  0.0640,  0.0266, -0.0315,  0.0453],\n",
       "                        [ 0.0216,  0.0590,  0.0177,  0.0216,  0.0462],\n",
       "                        [-0.0010, -0.0128,  0.0236,  0.0128, -0.0354]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0188,  0.0376,  0.0470, -0.0188, -0.0220],\n",
       "                        [-0.0481,  0.0073,  0.0376, -0.0167, -0.0199],\n",
       "                        [-0.0272, -0.0167, -0.0314,  0.0512, -0.0063],\n",
       "                        [-0.0460, -0.0021,  0.0460, -0.0418, -0.0554],\n",
       "                        [-0.0376, -0.0021, -0.0450, -0.0575, -0.0335]],\n",
       "              \n",
       "                       [[-0.0167, -0.0314,  0.0303, -0.0460, -0.0324],\n",
       "                        [ 0.0397,  0.0387, -0.0209,  0.0533, -0.0303],\n",
       "                        [ 0.0240,  0.0230,  0.0157,  0.0094,  0.0010],\n",
       "                        [-0.0209, -0.0450,  0.0178,  0.0345, -0.0335],\n",
       "                        [-0.0115, -0.0314,  0.0408, -0.0115,  0.0199]],\n",
       "              \n",
       "                       [[ 0.0125, -0.0376, -0.0460,  0.0251, -0.0491],\n",
       "                        [ 0.0544, -0.0125, -0.0125,  0.0355, -0.0125],\n",
       "                        [ 0.0136,  0.0261,  0.0000,  0.0554, -0.0178],\n",
       "                        [-0.0606, -0.0565,  0.0261, -0.0355,  0.0272],\n",
       "                        [ 0.0031, -0.0355, -0.0031, -0.0167, -0.0533]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0240,  0.0460, -0.0220,  0.0031, -0.0220],\n",
       "                        [-0.0094, -0.0596, -0.0429,  0.0460,  0.0523],\n",
       "                        [-0.0167,  0.0293,  0.0753,  0.0303, -0.0669],\n",
       "                        [ 0.0031,  0.0021, -0.0397,  0.0094, -0.0931],\n",
       "                        [ 0.0606,  0.0042,  0.0042,  0.0188, -0.0209]],\n",
       "              \n",
       "                       [[ 0.0209,  0.0052,  0.0146,  0.0303, -0.0073],\n",
       "                        [ 0.0554,  0.0209,  0.0167,  0.0220,  0.0261],\n",
       "                        [ 0.0031,  0.0774, -0.0648, -0.0397, -0.0167],\n",
       "                        [-0.0345, -0.0491,  0.0188,  0.0115, -0.0450],\n",
       "                        [ 0.0052, -0.0470, -0.0052,  0.0010, -0.0105]],\n",
       "              \n",
       "                       [[-0.0125,  0.0355,  0.0052, -0.0314, -0.0355],\n",
       "                        [ 0.0345,  0.0240,  0.0324, -0.0042,  0.0460],\n",
       "                        [ 0.0335,  0.0282,  0.0021, -0.0335, -0.0042],\n",
       "                        [ 0.0042, -0.0565, -0.0136,  0.0397, -0.0575],\n",
       "                        [-0.0366,  0.0146,  0.0167,  0.0366, -0.0533]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0351, -0.0202, -0.0094,  0.0675,  0.1107],\n",
       "                        [ 0.0607, -0.0094,  0.0418,  0.0661, -0.0054],\n",
       "                        [-0.0499, -0.0283, -0.0432,  0.0256, -0.0405],\n",
       "                        [ 0.0027,  0.0405, -0.0405,  0.0175, -0.0175],\n",
       "                        [-0.0256,  0.0526,  0.0229, -0.0175, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0351,  0.0405,  0.0324,  0.0324,  0.0580],\n",
       "                        [ 0.0081,  0.0513, -0.0108, -0.0108, -0.0256],\n",
       "                        [-0.0351, -0.0162, -0.0405,  0.0256,  0.0364],\n",
       "                        [-0.0567, -0.0256, -0.0121, -0.0324,  0.0175],\n",
       "                        [ 0.0405, -0.0459,  0.0297, -0.0135,  0.0310]],\n",
       "              \n",
       "                       [[ 0.0148, -0.0445, -0.0202,  0.0459,  0.0216],\n",
       "                        [-0.0054, -0.0216,  0.0000,  0.0027, -0.0162],\n",
       "                        [-0.0621,  0.0175,  0.0108, -0.0337, -0.0486],\n",
       "                        [ 0.0499,  0.0162, -0.0486,  0.0445, -0.0175],\n",
       "                        [ 0.0216, -0.0472,  0.0256,  0.0513,  0.0391]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0027,  0.0013, -0.0378,  0.0580,  0.0864],\n",
       "                        [-0.0081,  0.0324, -0.0337, -0.0405, -0.0472],\n",
       "                        [ 0.0513, -0.0283,  0.0378,  0.0648,  0.0445],\n",
       "                        [-0.0067,  0.0148, -0.0081,  0.0013,  0.0445],\n",
       "                        [ 0.0202,  0.0054, -0.0310,  0.0445,  0.0108]],\n",
       "              \n",
       "                       [[-0.0135,  0.0526,  0.0162, -0.0108,  0.0135],\n",
       "                        [ 0.0472,  0.0256,  0.0378, -0.0526, -0.0027],\n",
       "                        [ 0.0459,  0.0108,  0.0405, -0.0337, -0.0202],\n",
       "                        [ 0.1188, -0.0432, -0.0013,  0.0445, -0.0054],\n",
       "                        [ 0.0837,  0.0283,  0.0243, -0.0202,  0.0094]],\n",
       "              \n",
       "                       [[-0.0486,  0.0297, -0.0324, -0.0324,  0.0054],\n",
       "                        [ 0.0148, -0.0243, -0.0283,  0.0256, -0.0067],\n",
       "                        [-0.0229,  0.0243,  0.0054, -0.0513, -0.0283],\n",
       "                        [-0.0202,  0.0229,  0.0202,  0.0162,  0.0634],\n",
       "                        [ 0.0526, -0.0054,  0.0351,  0.0243,  0.0486]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0340, -0.0208, -0.0057,  0.0415,  0.0925],\n",
       "                        [ 0.0264,  0.0000, -0.0623,  0.0359,  0.0604],\n",
       "                        [-0.0415,  0.0547,  0.0359, -0.0434, -0.0396],\n",
       "                        [ 0.0359, -0.0378, -0.0585, -0.0547,  0.0491],\n",
       "                        [ 0.0415, -0.0019,  0.0585,  0.0661,  0.0170]],\n",
       "              \n",
       "                       [[-0.0302,  0.0170, -0.0453,  0.0189, -0.0038],\n",
       "                        [ 0.0057, -0.0038, -0.0396, -0.0661, -0.0189],\n",
       "                        [-0.0378,  0.0604, -0.0113,  0.0396,  0.0208],\n",
       "                        [ 0.0434,  0.0189,  0.0359,  0.0113,  0.0321],\n",
       "                        [ 0.0547,  0.0321,  0.0604,  0.0585,  0.0585]],\n",
       "              \n",
       "                       [[-0.0038,  0.0283,  0.0302,  0.0321, -0.0378],\n",
       "                        [-0.0396, -0.0396, -0.0321, -0.0585, -0.0151],\n",
       "                        [-0.0302,  0.0076,  0.0604, -0.0491, -0.0245],\n",
       "                        [ 0.0434,  0.0491,  0.0019, -0.0208, -0.0151],\n",
       "                        [ 0.0585,  0.0227,  0.0340,  0.0434,  0.0359]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0057,  0.0566,  0.0151,  0.0321,  0.0227],\n",
       "                        [-0.0227,  0.0359, -0.0340,  0.0208, -0.0170],\n",
       "                        [-0.0302,  0.0661, -0.0076, -0.0132,  0.0547],\n",
       "                        [-0.0227,  0.0698,  0.0774,  0.0227,  0.0887],\n",
       "                        [-0.0359, -0.0359,  0.0189,  0.0151,  0.0812]],\n",
       "              \n",
       "                       [[-0.0321, -0.0321,  0.0132, -0.0038,  0.0245],\n",
       "                        [ 0.0415, -0.0472,  0.0245, -0.0094, -0.0038],\n",
       "                        [ 0.0227, -0.0094,  0.0208,  0.0585, -0.0302],\n",
       "                        [ 0.0529,  0.0076, -0.0170,  0.0359,  0.0000],\n",
       "                        [ 0.0076,  0.0434,  0.0415,  0.0396,  0.0359]],\n",
       "              \n",
       "                       [[-0.0245,  0.0189, -0.0396, -0.0094,  0.0113],\n",
       "                        [ 0.0340, -0.0245, -0.0340,  0.0094, -0.0227],\n",
       "                        [-0.0547, -0.0076,  0.0566, -0.0378,  0.0076],\n",
       "                        [ 0.0566,  0.0547,  0.0359,  0.0396, -0.0378],\n",
       "                        [-0.0170,  0.0264,  0.0208,  0.0491,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0045,  0.0123, -0.0419, -0.0493,  0.0185],\n",
       "                        [ 0.0041, -0.0226,  0.0341, -0.0464, -0.0501],\n",
       "                        [-0.0477, -0.0177, -0.0238,  0.0201,  0.0444],\n",
       "                        [ 0.0415, -0.0127, -0.0398, -0.0041, -0.0353],\n",
       "                        [-0.0415,  0.0119, -0.0444, -0.0464, -0.0193]],\n",
       "              \n",
       "                       [[-0.0357,  0.0234,  0.0205, -0.0526, -0.0316],\n",
       "                        [-0.0378,  0.0185,  0.0419, -0.0345,  0.0016],\n",
       "                        [-0.0078,  0.0025, -0.0296,  0.0111,  0.0078],\n",
       "                        [-0.0435, -0.0156, -0.0140, -0.0501,  0.0197],\n",
       "                        [-0.0066, -0.0246, -0.0370,  0.0362, -0.0148]],\n",
       "              \n",
       "                       [[-0.0152, -0.0119, -0.0271, -0.0016, -0.0210],\n",
       "                        [ 0.0218,  0.0435, -0.0012, -0.0263, -0.0337],\n",
       "                        [ 0.0370, -0.0485, -0.0193, -0.0222, -0.0049],\n",
       "                        [-0.0242,  0.0205, -0.0275,  0.0448, -0.0362],\n",
       "                        [ 0.0411, -0.0509,  0.0070, -0.0407, -0.0214]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0345,  0.0119, -0.0025,  0.0016, -0.0300],\n",
       "                        [-0.0407,  0.0320,  0.0353,  0.0308,  0.0123],\n",
       "                        [-0.0382, -0.0456, -0.0419,  0.0099,  0.0419],\n",
       "                        [-0.0119,  0.0074,  0.0337,  0.0210,  0.0448],\n",
       "                        [ 0.0382, -0.0419, -0.0008, -0.0497, -0.0160]],\n",
       "              \n",
       "                       [[ 0.0193, -0.0255,  0.0362,  0.0181, -0.0004],\n",
       "                        [ 0.0337,  0.0197,  0.0148, -0.0362,  0.0082],\n",
       "                        [ 0.0197, -0.0049,  0.0078, -0.0325, -0.0403],\n",
       "                        [ 0.0123, -0.0431,  0.0341,  0.0053,  0.0283],\n",
       "                        [ 0.0193, -0.0086, -0.0099,  0.0275,  0.0238]],\n",
       "              \n",
       "                       [[-0.0197, -0.0407, -0.0214, -0.0062,  0.0353],\n",
       "                        [-0.0201, -0.0218,  0.0148, -0.0246, -0.0259],\n",
       "                        [ 0.0345, -0.0427, -0.0325,  0.0415, -0.0481],\n",
       "                        [-0.0025, -0.0025,  0.0246, -0.0210,  0.0066],\n",
       "                        [-0.0374,  0.0103,  0.0456,  0.0123,  0.0267]]]],\n",
       "                     size=(120, 16, 5, 5), dtype=torch.qint8,\n",
       "                     quantization_scheme=torch.per_channel_affine,\n",
       "                     scale=tensor([0.0009, 0.0010, 0.0010, 0.0019, 0.0010, 0.0011, 0.0011, 0.0008, 0.0010,\n",
       "                      0.0011, 0.0011, 0.0011, 0.0008, 0.0010, 0.0013, 0.0007, 0.0010, 0.0018,\n",
       "                      0.0012, 0.0012, 0.0016, 0.0012, 0.0010, 0.0011, 0.0004, 0.0016, 0.0004,\n",
       "                      0.0004, 0.0004, 0.0009, 0.0015, 0.0009, 0.0004, 0.0010, 0.0009, 0.0015,\n",
       "                      0.0009, 0.0009, 0.0012, 0.0004, 0.0007, 0.0011, 0.0008, 0.0004, 0.0010,\n",
       "                      0.0016, 0.0009, 0.0013, 0.0009, 0.0014, 0.0004, 0.0010, 0.0011, 0.0012,\n",
       "                      0.0011, 0.0008, 0.0009, 0.0014, 0.0018, 0.0015, 0.0010, 0.0010, 0.0004,\n",
       "                      0.0008, 0.0010, 0.0010, 0.0010, 0.0009, 0.0007, 0.0008, 0.0009, 0.0011,\n",
       "                      0.0015, 0.0013, 0.0010, 0.0011, 0.0010, 0.0009, 0.0011, 0.0004, 0.0009,\n",
       "                      0.0010, 0.0010, 0.0009, 0.0008, 0.0013, 0.0009, 0.0010, 0.0010, 0.0004,\n",
       "                      0.0009, 0.0007, 0.0013, 0.0010, 0.0012, 0.0009, 0.0013, 0.0015, 0.0013,\n",
       "                      0.0011, 0.0009, 0.0004, 0.0011, 0.0013, 0.0013, 0.0012, 0.0004, 0.0004,\n",
       "                      0.0009, 0.0013, 0.0010, 0.0012, 0.0011, 0.0004, 0.0004, 0.0011, 0.0009,\n",
       "                      0.0013, 0.0019, 0.0004], dtype=torch.float64),\n",
       "                     zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                     axis=0)),\n",
       "             ('feature_extractor.6.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0183, -0.0326, -0.0136,  0.0144, -0.0378, -0.0459, -0.0325, -0.0006,\n",
       "                       0.0566,  0.0322, -0.0276, -0.0442, -0.0120,  0.0336, -0.0313, -0.0100,\n",
       "                      -0.0055,  0.0147, -0.0060,  0.0210, -0.0150,  0.0181,  0.0071, -0.0626,\n",
       "                      -0.0255,  0.0603, -0.0395, -0.0101, -0.0062,  0.0207,  0.0485, -0.0063,\n",
       "                      -0.0452,  0.0473, -0.0079,  0.0313, -0.0185,  0.0092,  0.0325,  0.0019,\n",
       "                      -0.0217, -0.0288, -0.0479,  0.0220, -0.0840,  0.0250,  0.0331,  0.0745,\n",
       "                      -0.0192,  0.0690,  0.0286,  0.0477, -0.0034, -0.0359,  0.0900,  0.0382,\n",
       "                      -0.0178,  0.0409, -0.0062,  0.0685,  0.0101, -0.0489,  0.0431,  0.0525,\n",
       "                      -0.0506,  0.0563,  0.0228,  0.0052,  0.0268,  0.0350,  0.0183, -0.0176,\n",
       "                      -0.0587,  0.0541, -0.0139,  0.0442, -0.0310,  0.0086, -0.0556, -0.0320,\n",
       "                       0.0745,  0.0259,  0.0448,  0.0533, -0.0058,  0.1210, -0.0155,  0.0307,\n",
       "                      -0.0100, -0.0155,  0.0194,  0.0208,  0.0720,  0.0718,  0.0249, -0.0400,\n",
       "                      -0.0107, -0.0246,  0.0328, -0.0416, -0.0166, -0.0157,  0.0581,  0.0544,\n",
       "                       0.0433, -0.0582, -0.0379,  0.0421, -0.0122,  0.0097,  0.0090,  0.0685,\n",
       "                       0.0592, -0.0112,  0.0269, -0.0563, -0.0059, -0.0263,  0.0306, -0.0523],\n",
       "                     requires_grad=True)),\n",
       "             ('feature_extractor.6.scale', tensor(0.5519)),\n",
       "             ('feature_extractor.6.zero_point', tensor(60)),\n",
       "             ('classifier.0.scale', tensor(0.4589)),\n",
       "             ('classifier.0.zero_point', tensor(62)),\n",
       "             ('classifier.0._packed_params.dtype', torch.qint8),\n",
       "             ('classifier.0._packed_params._packed_params',\n",
       "              (tensor([[ 0.0723,  0.0675,  0.0663,  ..., -0.0325, -0.0796, -0.0458],\n",
       "                       [-0.0592,  0.0797, -0.0036,  ...,  0.0012,  0.0797, -0.0664],\n",
       "                       [ 0.0214, -0.0346, -0.0905,  ..., -0.0539, -0.0163, -0.0763],\n",
       "                       ...,\n",
       "                       [ 0.0000,  0.0693,  0.0652,  ..., -0.0829,  0.0204,  0.0190],\n",
       "                       [ 0.0674,  0.0289, -0.0060,  ..., -0.0313,  0.0770,  0.0782],\n",
       "                       [-0.0402, -0.0706, -0.0341,  ...,  0.0633, -0.0061, -0.0438]],\n",
       "                      size=(84, 120), dtype=torch.qint8,\n",
       "                      quantization_scheme=torch.per_channel_affine,\n",
       "                      scale=tensor([0.0012, 0.0012, 0.0010, 0.0013, 0.0011, 0.0008, 0.0010, 0.0012, 0.0011,\n",
       "                       0.0011, 0.0012, 0.0013, 0.0007, 0.0007, 0.0014, 0.0011, 0.0007, 0.0012,\n",
       "                       0.0015, 0.0009, 0.0012, 0.0013, 0.0010, 0.0011, 0.0008, 0.0016, 0.0013,\n",
       "                       0.0013, 0.0015, 0.0013, 0.0017, 0.0010, 0.0010, 0.0008, 0.0013, 0.0012,\n",
       "                       0.0018, 0.0012, 0.0015, 0.0016, 0.0011, 0.0012, 0.0011, 0.0016, 0.0012,\n",
       "                       0.0011, 0.0011, 0.0012, 0.0008, 0.0011, 0.0017, 0.0011, 0.0015, 0.0012,\n",
       "                       0.0011, 0.0012, 0.0015, 0.0012, 0.0017, 0.0010, 0.0012, 0.0007, 0.0014,\n",
       "                       0.0007, 0.0011, 0.0015, 0.0007, 0.0008, 0.0012, 0.0018, 0.0011, 0.0013,\n",
       "                       0.0010, 0.0011, 0.0013, 0.0016, 0.0008, 0.0012, 0.0014, 0.0008, 0.0011,\n",
       "                       0.0014, 0.0012, 0.0012], dtype=torch.float64),\n",
       "                      zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                      axis=0),\n",
       "               Parameter containing:\n",
       "               tensor([ 0.0794,  0.0680, -0.0403,  0.0263, -0.0632, -0.0866,  0.0577, -0.0526,\n",
       "                        0.0436,  0.0258,  0.0280,  0.0081, -0.0559,  0.0394,  0.0210,  0.0649,\n",
       "                       -0.0382,  0.1325,  0.0049, -0.0222,  0.0472,  0.1008,  0.0321,  0.1001,\n",
       "                       -0.0363, -0.0331,  0.0688, -0.0258,  0.0596,  0.0543, -0.0156,  0.0881,\n",
       "                        0.0089, -0.0506,  0.1113,  0.0596,  0.0691,  0.0968,  0.0306, -0.0028,\n",
       "                        0.0380, -0.0701, -0.0169,  0.0669,  0.0666, -0.0718,  0.0652, -0.0294,\n",
       "                       -0.0403, -0.0028, -0.0761,  0.0732,  0.0812, -0.0535, -0.0652,  0.0154,\n",
       "                       -0.0497,  0.0607,  0.0505,  0.1212, -0.1517, -0.0611,  0.0700, -0.0395,\n",
       "                        0.0328, -0.0525,  0.0725, -0.0351,  0.0097, -0.1016, -0.0020, -0.0307,\n",
       "                        0.0533, -0.0263,  0.0231,  0.0746, -0.0427,  0.0162, -0.0116, -0.0155,\n",
       "                        0.0505, -0.0374,  0.0124,  0.0181], requires_grad=True))),\n",
       "             ('classifier.2.scale', tensor(0.3701)),\n",
       "             ('classifier.2.zero_point', tensor(66)),\n",
       "             ('classifier.2._packed_params.dtype', torch.qint8),\n",
       "             ('classifier.2._packed_params._packed_params',\n",
       "              (tensor([[-0.0723, -0.0904,  0.0868,  0.0844,  0.0157, -0.0844,  0.0892, -0.0964,\n",
       "                        -0.0989, -0.0350, -0.0108,  0.0217, -0.0976,  0.0060,  0.1037, -0.1543,\n",
       "                         0.0964,  0.0386,  0.0374,  0.0434, -0.0916,  0.0506,  0.0711, -0.1049,\n",
       "                         0.0265, -0.1495, -0.0579, -0.0603,  0.0205,  0.0856,  0.1145,  0.0108,\n",
       "                         0.1157, -0.0868, -0.1109,  0.0844,  0.0217, -0.0904, -0.0277, -0.0494,\n",
       "                         0.0904, -0.1386, -0.0518, -0.0952, -0.0663,  0.1181,  0.0989,  0.0157,\n",
       "                        -0.0723,  0.0675,  0.1037, -0.0362,  0.0470,  0.0289,  0.0976,  0.0482,\n",
       "                        -0.0108, -0.0940,  0.0470, -0.0687,  0.0374,  0.0651, -0.1109, -0.0928,\n",
       "                         0.0277, -0.0145,  0.0157, -0.0832,  0.0856, -0.1001,  0.0603, -0.1338,\n",
       "                        -0.0289,  0.0663, -0.1519, -0.1495, -0.0675,  0.0615, -0.0603, -0.0844,\n",
       "                         0.0350,  0.0458, -0.0374,  0.0265],\n",
       "                       [ 0.0702, -0.0454, -0.0798, -0.0564, -0.0317, -0.0854, -0.0207, -0.0289,\n",
       "                         0.0551, -0.0055,  0.0936,  0.1046,  0.0840, -0.0138, -0.1294,  0.0702,\n",
       "                        -0.0950,  0.0881, -0.1129,  0.1322,  0.0468,  0.0069,  0.0069,  0.1115,\n",
       "                        -0.1046,  0.0688, -0.1652,  0.0468,  0.1115, -0.1143,  0.1060, -0.1156,\n",
       "                        -0.1418,  0.0385,  0.0592, -0.0055, -0.0840,  0.1404,  0.0909, -0.0716,\n",
       "                         0.0399,  0.0633, -0.1198, -0.0950, -0.1101, -0.1156, -0.0441, -0.1267,\n",
       "                        -0.0165, -0.0385,  0.1170,  0.1074,  0.1184, -0.1762, -0.0220,  0.0757,\n",
       "                         0.1170, -0.0578, -0.0207, -0.1404, -0.0977,  0.0289,  0.0069,  0.0564,\n",
       "                        -0.0069,  0.1005, -0.0771, -0.0454,  0.1046, -0.0702, -0.0991,  0.0895,\n",
       "                        -0.0909,  0.0482,  0.0743, -0.0826, -0.0413,  0.0041,  0.0124,  0.1335,\n",
       "                         0.0922,  0.0317,  0.1088, -0.1088],\n",
       "                       [-0.0854,  0.0464,  0.0405, -0.0869,  0.1169,  0.0704, -0.0884, -0.0539,\n",
       "                         0.0569,  0.1318,  0.0165, -0.1199,  0.0105, -0.0764,  0.0135, -0.0434,\n",
       "                         0.0659, -0.1363, -0.0479, -0.0300, -0.0509,  0.0120, -0.1109,  0.0674,\n",
       "                        -0.1034,  0.0704, -0.0509,  0.0390, -0.1229, -0.0974, -0.0315,  0.0180,\n",
       "                        -0.0405, -0.0614,  0.0225,  0.1154,  0.1258,  0.0210,  0.1034, -0.1139,\n",
       "                         0.1154,  0.0345,  0.0135, -0.1169, -0.0614,  0.0764, -0.1423, -0.0075,\n",
       "                        -0.0434,  0.1273,  0.0105,  0.0419,  0.1004,  0.0749,  0.0899,  0.0030,\n",
       "                        -0.1738,  0.0584, -0.0030,  0.1004,  0.0270,  0.0569, -0.1903, -0.0479,\n",
       "                         0.0390,  0.0809,  0.0809,  0.0614, -0.1513,  0.0360,  0.0180, -0.0285,\n",
       "                        -0.0195, -0.1034,  0.1303, -0.1303, -0.0449,  0.1094, -0.0464,  0.0884,\n",
       "                         0.1079,  0.1139, -0.0674, -0.1199],\n",
       "                       [ 0.0193,  0.0219,  0.0412,  0.0709, -0.0142,  0.0309,  0.0296, -0.0129,\n",
       "                         0.0735, -0.1392, -0.0657,  0.0477, -0.0773,  0.0438,  0.0799,  0.0039,\n",
       "                         0.0219, -0.0735, -0.0155,  0.0773, -0.1121,  0.0993, -0.0619, -0.1212,\n",
       "                        -0.0374,  0.1134, -0.1109,  0.1005, -0.0400, -0.0954, -0.1495,  0.0180,\n",
       "                        -0.1225,  0.0219,  0.0348, -0.0155,  0.1173,  0.0877, -0.1353, -0.1083,\n",
       "                        -0.0980,  0.0773,  0.0142,  0.0284, -0.1044,  0.1031, -0.0451,  0.1018,\n",
       "                         0.0709, -0.0090, -0.1005,  0.0696, -0.1418, -0.1147, -0.1573,  0.0090,\n",
       "                        -0.1650,  0.0580,  0.0760,  0.0026,  0.0902, -0.0722, -0.1044,  0.0064,\n",
       "                         0.0335,  0.1186,  0.0877,  0.1160, -0.0516,  0.0580, -0.0993,  0.1109,\n",
       "                        -0.1160,  0.0954, -0.0180, -0.1495,  0.0425,  0.0180,  0.0980, -0.1186,\n",
       "                         0.0877, -0.0232,  0.0103, -0.1366],\n",
       "                       [ 0.1106,  0.0762,  0.0701,  0.0934, -0.0258,  0.0860,  0.0873,  0.0356,\n",
       "                        -0.0221, -0.0959, -0.1266, -0.0455, -0.0787, -0.1045,  0.0246, -0.0381,\n",
       "                        -0.0442, -0.0553,  0.0885,  0.0885, -0.0074, -0.0074, -0.1549, -0.1573,\n",
       "                        -0.0995,  0.0885,  0.0381, -0.0160, -0.1254,  0.1057, -0.0061,  0.0578,\n",
       "                         0.0258, -0.0971,  0.1094, -0.0123, -0.0713, -0.1131, -0.0135,  0.0086,\n",
       "                        -0.0025, -0.0455,  0.1094,  0.0578,  0.1241, -0.0393, -0.0860, -0.0885,\n",
       "                        -0.0750, -0.0565,  0.0602, -0.1069, -0.0356,  0.0393,  0.0553,  0.0602,\n",
       "                         0.0049, -0.1266, -0.1327,  0.1032, -0.0578, -0.0479, -0.0614, -0.0688,\n",
       "                        -0.0492, -0.1057, -0.0270, -0.0701,  0.1082,  0.0995,  0.0381, -0.0197,\n",
       "                        -0.0971, -0.1057,  0.0283,  0.1315, -0.0467,  0.0344,  0.0320,  0.0049,\n",
       "                        -0.0836, -0.1020, -0.1499,  0.0713],\n",
       "                       [-0.0222,  0.0814,  0.0681,  0.0370, -0.0548, -0.0044, -0.0192, -0.0089,\n",
       "                        -0.0903,  0.0237, -0.0266, -0.0607,  0.0326, -0.0592,  0.1140,  0.0370,\n",
       "                        -0.0488,  0.0725,  0.0237, -0.1880,  0.0163, -0.0370,  0.0696, -0.1317,\n",
       "                        -0.0148,  0.0370,  0.1169, -0.0577, -0.0651,  0.1332, -0.0059,  0.0859,\n",
       "                         0.0918, -0.0281, -0.0118, -0.1821,  0.0696,  0.0725,  0.1613, -0.0252,\n",
       "                         0.0533,  0.0918, -0.0681, -0.1169, -0.0785,  0.0015,  0.0844,  0.1155,\n",
       "                         0.0252, -0.0829, -0.0903,  0.0888, -0.1806, -0.0814, -0.1051, -0.1051,\n",
       "                        -0.1081, -0.0311,  0.0785,  0.0711, -0.0666, -0.0873,  0.0548, -0.0252,\n",
       "                         0.1140, -0.0859, -0.0518, -0.1214,  0.1007, -0.1480,  0.0044, -0.0222,\n",
       "                         0.0400, -0.0829, -0.0681,  0.0355, -0.1021, -0.0059,  0.0992,  0.1066,\n",
       "                        -0.0725, -0.1273,  0.0622, -0.0459],\n",
       "                       [-0.1675,  0.1070,  0.0293, -0.2003,  0.0898, -0.0829,  0.0898, -0.1934,\n",
       "                        -0.0276, -0.0863, -0.0552, -0.0984,  0.1001, -0.0069,  0.0725, -0.1174,\n",
       "                         0.1001,  0.1105,  0.0173, -0.0639,  0.1398,  0.0742, -0.1364, -0.1416,\n",
       "                         0.0777,  0.0328,  0.0880,  0.1209, -0.1019, -0.0345, -0.0932,  0.0035,\n",
       "                         0.0673,  0.0035,  0.0173, -0.0311,  0.0207,  0.0224,  0.0155, -0.0138,\n",
       "                         0.0414,  0.0276,  0.0673, -0.1519,  0.0673, -0.0777,  0.0742, -0.0432,\n",
       "                         0.0363,  0.0984, -0.0432, -0.1139,  0.0967, -0.0656, -0.0742,  0.1001,\n",
       "                        -0.0967, -0.0725,  0.0932,  0.0449, -0.0328, -0.0035, -0.0760, -0.0760,\n",
       "                        -0.0345, -0.2193,  0.0397, -0.0932,  0.0829,  0.0276,  0.0069, -0.0535,\n",
       "                         0.1571,  0.1157, -0.1692, -0.0656,  0.0501, -0.0691, -0.1951, -0.0967,\n",
       "                         0.0622, -0.0190,  0.1105,  0.1537],\n",
       "                       [ 0.1123, -0.1280, -0.1631,  0.0719,  0.0824, -0.0930, -0.1140, -0.1087,\n",
       "                        -0.0789, -0.0737,  0.0649,  0.0000,  0.0351, -0.0859, -0.1526,  0.0684,\n",
       "                         0.0877,  0.0491, -0.0526, -0.0263, -0.1140,  0.1456,  0.1315, -0.0298,\n",
       "                        -0.0298, -0.0754, -0.0228,  0.1087,  0.0351, -0.0859, -0.0105,  0.0526,\n",
       "                        -0.0719, -0.0246, -0.0789, -0.0246,  0.0807, -0.0912,  0.1280, -0.0088,\n",
       "                         0.0631,  0.0439,  0.0754,  0.1193,  0.0965,  0.0544,  0.0316,  0.0246,\n",
       "                         0.0684,  0.0491, -0.0596, -0.0281,  0.1052,  0.0403,  0.0193,  0.0877,\n",
       "                        -0.0789,  0.0807,  0.0631,  0.0754, -0.1508, -0.0386, -0.0246, -0.0210,\n",
       "                        -0.0210,  0.0859, -0.0807,  0.1491, -0.0421,  0.1087, -0.0474, -0.0754,\n",
       "                         0.1456, -0.0228,  0.0351, -0.1280,  0.0123, -0.1263,  0.0579,  0.1403,\n",
       "                         0.0088,  0.0368,  0.2228, -0.0702],\n",
       "                       [-0.1239, -0.0452,  0.0786, -0.1376,  0.1239, -0.0845, -0.0904,  0.0413,\n",
       "                        -0.0059, -0.0590, -0.0334,  0.0924, -0.0413, -0.0098, -0.0433,  0.0688,\n",
       "                        -0.0865, -0.1553,  0.0531,  0.0904,  0.1239, -0.0963, -0.0256,  0.0295,\n",
       "                        -0.1199, -0.1514, -0.1101,  0.1081, -0.0118,  0.0000, -0.2517,  0.0570,\n",
       "                        -0.0059,  0.0059, -0.0963, -0.0885,  0.1003, -0.0138, -0.1730,  0.1081,\n",
       "                         0.0708,  0.0767,  0.0668,  0.0904, -0.0708,  0.1003,  0.0629,  0.0334,\n",
       "                         0.0374, -0.0118, -0.1573,  0.1101,  0.0177, -0.0275, -0.1357, -0.0020,\n",
       "                         0.0786, -0.0570,  0.0118, -0.0983,  0.1298,  0.0767, -0.1337,  0.0550,\n",
       "                         0.0511,  0.0472,  0.0806,  0.0098,  0.0256,  0.0806, -0.0275, -0.0295,\n",
       "                        -0.0157,  0.0826, -0.1160,  0.1003, -0.0904, -0.1042,  0.0197,  0.0511,\n",
       "                        -0.0138,  0.0885, -0.0570, -0.0668],\n",
       "                       [ 0.0396, -0.0297,  0.0057,  0.1315,  0.0014,  0.0975,  0.1032, -0.1103,\n",
       "                         0.0580, -0.0693,  0.1244,  0.0226, -0.0862,  0.0551, -0.0028,  0.0608,\n",
       "                        -0.0891, -0.0636,  0.0975, -0.0028, -0.0608, -0.0254,  0.1202, -0.0537,\n",
       "                         0.0608, -0.1809, -0.0368, -0.1527,  0.1131,  0.0495, -0.1145,  0.1272,\n",
       "                        -0.0636,  0.0876,  0.1357, -0.0438, -0.0919,  0.0848, -0.0650,  0.1145,\n",
       "                        -0.1300, -0.1060,  0.0891, -0.0693,  0.0424, -0.0014, -0.0580, -0.1032,\n",
       "                         0.0325,  0.0424, -0.0311, -0.1046,  0.1173, -0.0127, -0.1767, -0.0919,\n",
       "                         0.0636,  0.0749,  0.0212,  0.0664,  0.0820, -0.0170,  0.1060, -0.0792,\n",
       "                        -0.1244,  0.0876,  0.0891,  0.0580,  0.0000, -0.0198,  0.0396, -0.0919,\n",
       "                        -0.0961, -0.1032, -0.1611,  0.0806, -0.0028,  0.1032,  0.0862, -0.0834,\n",
       "                        -0.0042,  0.1230, -0.0622, -0.0933]], size=(10, 84),\n",
       "                      dtype=torch.qint8, quantization_scheme=torch.per_channel_affine,\n",
       "                      scale=tensor([0.0012, 0.0014, 0.0015, 0.0013, 0.0012, 0.0015, 0.0017, 0.0018, 0.0020,\n",
       "                       0.0014], dtype=torch.float64),\n",
       "                      zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), axis=0),\n",
       "               Parameter containing:\n",
       "               tensor([-0.0927, -0.0793, -0.0181, -0.0321, -0.0242,  0.0465, -0.0984, -0.0501,\n",
       "                        0.0395,  0.0516], requires_grad=True)))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model = torch.quantization.prepare(model)\n",
    "\n",
    "for X, _ in dataset.valid_dl:\n",
    "    model(X)\n",
    "\n",
    "int8_model = torch.quantization.convert(model, inplace=False)\n",
    "\n",
    "for name, param in int8_model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.data.shape)\n",
    "    print(param.data)\n",
    "\n",
    "int8_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9516)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(int8_model, dataset.valid_dl, 'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
